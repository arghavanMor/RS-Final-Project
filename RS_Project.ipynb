{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project is about recommending developers to solve a bug based on their source code. I used a supervised dataset [any commit which are related to a bug has an asigned author (developers)]. I used LDA method to find the domians (topics) of each developer, then I asign them to a bug based on their domain. Also, I used a classification method (KNN) as a baseline to compare the result of LDA with the baseline.\n",
    "For dataset I used two method that I called them \"NLP\" and \"AST\". For NLP dataset, I used language processing tokenizer to extract the tokens within a source code. For \"AST\" dataset, I used Abstract Syntax Tree and considered each node of tree as a token.\n",
    "\"Pydriller\" that I import below is a libriary to drill (scrape) the github repository. I extracted one year data (commit) for 15 developers from \"Panda\" Repository.\n",
    "The structure of report is as below:\n",
    "1. extracting data of github for NLP study\n",
    "2. LDA method on NLP data\n",
    "3. KNN method on NLP data\n",
    "4. extracting data for AST study\n",
    "5. a step by step explanation of how AST function works and find the tokens\n",
    "6. Run the AST function on whole dataset to extract tokens\n",
    "7. KNN method on AST data\n",
    "8. LDA method on AST data\n",
    "9. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydriller as pyd\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a path of panda repository\n",
    "path = \"https://github.com/pandas-dev/pandas.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I defined the one year duration to extract the data\n",
    "dt1 = datetime(2018, 10, 1)\n",
    "dt2 = datetime(2019, 10, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. extracting data of github for NLP stud\n",
    "  * df_source is stored those commits which are related to developement, test, optimization, etc.\n",
    "  * df_bug is stored those commits which are related to bugs\n",
    "  * good point about panda repository is that those commits which are related to bugs, starts with \"BUG:\" in title\n",
    "  * This is a dataset for \"NLP\" part. Here, I extract 'diff' file. 'diff' is one of the objects of commit in git repository. It shows the difference between two files after submmiting a commit. 'diff' file contains all lines that developer add/remove within a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a dataframe to store commits related to developement\n",
    "df_source = pd.DataFrame(columns=['commit_ID', 'Author', 'Date', 'file_name', 'msg', 'diff'])\n",
    "# a dataframe of those commits which are related to bugs\n",
    "df_bug = pd.DataFrame(columns=['commit_ID', 'Author', 'file_name', 'msg', 'diff'])\n",
    "#a list of 15 authors\n",
    "Authors = ['Jeff Reback','jbrockmendel','Joris Van den Bossche','Tom Augspurger','gfyoung','Matthew Roeschke',\n",
    "           'Terji Petersen','William Ayd','Simon Hawkins','Jeremy Schendel','Marc Garcia',\n",
    "           'Pietro Battiston','h-vetinari','Christopher Whelan','alimcmaster1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in a loop, I extract all commits for list of \"Authors\" and between \"dt1\" and \"dt2\". Also, I seperated bug commits in 'df_bug' dataframe.\n",
    "- **please be noted that below for loop takes time around 30 minutes to be run completely. Becuase it is extracting one year commits of 15 developers which is a big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <finalize object at 0x1adfa503820; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\weakref.py\", line 552, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\tempfile.py\", line 795, in _cleanup\n",
      "    _shutil.rmtree(name)\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 513, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 392, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 392, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 392, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 397, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 395, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\morad\\\\AppData\\\\Local\\\\Temp\\\\tmpodcq80c3\\\\pandas\\\\.git\\\\objects\\\\pack\\\\pack-58449f852a483ed971765a37e5764e30085fe216.idx'\n"
     ]
    }
   ],
   "source": [
    "for commit in pyd.RepositoryMining(path_to_repo=path, since=dt1, to=dt2, only_authors=Authors).traverse_commits():\n",
    "    for modified_file in commit.modifications:\n",
    "        if modified_file.filename.endswith(\".py\"):\n",
    "            if commit.msg.startswith(\"BUG\"):\n",
    "                df_bug = df_bug.append({'commit_ID': commit.hash, 'Author': commit.author.name,\n",
    "                                        'Date': commit.author_date,'msg': commit.msg,\n",
    "                                        'file_name': modified_file.filename,\n",
    "                                        'diff': modified_file.diff}, ignore_index=True)\n",
    "                #print(\"BUG\", commit.hash, commit.author.name, commit.author_date,commit.msg,\n",
    "                                           #modified_file.filename, flush=True)\n",
    "            else:\n",
    "                df_source = df_source.append({'commit_ID': commit.hash, 'Author': commit.author.name,\n",
    "                                                 'Date': commit.author_date,'msg': commit.msg,\n",
    "                                                 'file_name': modified_file.filename,\n",
    "                                                 'diff': modified_file.diff}, ignore_index=True)\n",
    "                #print(\"Code\", commit.hash, commit.author.name, commit.msg,commit.author_date,\n",
    "                        # modified_file.filename, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I save both dataset into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source.to_csv(r'C:\\GH-Dataset\\source_Data.csv', index=None, header=True)\n",
    "df_bug.to_csv(r'C:\\GH-Dataset\\bug_Data.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>file_name</th>\n",
       "      <th>msg</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6247da0db4835ff723126640145b4fad3ce17343</td>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>2018-10-02 08:50:41-05:00</td>\n",
       "      <td>conftest.py</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>@@ -31,12 +31,24 @@ def all_data(request, data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6247da0db4835ff723126640145b4fad3ce17343</td>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>2018-10-02 08:50:41-05:00</td>\n",
       "      <td>test_decimal.py</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>@@ -30,14 +30,6 @@ def data_missing():\\n     r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6247da0db4835ff723126640145b4fad3ce17343</td>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>2018-10-02 08:50:41-05:00</td>\n",
       "      <td>test_categorical.py</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>@@ -45,15 +45,6 @@ def data_missing():\\n     r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6247da0db4835ff723126640145b4fad3ce17343</td>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>2018-10-02 08:50:41-05:00</td>\n",
       "      <td>test_integer.py</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>@@ -47,14 +47,6 @@ def data_missing(dtype):\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6247da0db4835ff723126640145b4fad3ce17343</td>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>2018-10-02 08:50:41-05:00</td>\n",
       "      <td>test_interval.py</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>@@ -47,15 +47,6 @@ def data_missing():\\n     r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  commit_ID          Author  \\\n",
       "0  6247da0db4835ff723126640145b4fad3ce17343  Tom Augspurger   \n",
       "1  6247da0db4835ff723126640145b4fad3ce17343  Tom Augspurger   \n",
       "2  6247da0db4835ff723126640145b4fad3ce17343  Tom Augspurger   \n",
       "3  6247da0db4835ff723126640145b4fad3ce17343  Tom Augspurger   \n",
       "4  6247da0db4835ff723126640145b4fad3ce17343  Tom Augspurger   \n",
       "\n",
       "                        Date            file_name  \\\n",
       "0  2018-10-02 08:50:41-05:00          conftest.py   \n",
       "1  2018-10-02 08:50:41-05:00      test_decimal.py   \n",
       "2  2018-10-02 08:50:41-05:00  test_categorical.py   \n",
       "3  2018-10-02 08:50:41-05:00      test_integer.py   \n",
       "4  2018-10-02 08:50:41-05:00     test_interval.py   \n",
       "\n",
       "                                                 msg  \\\n",
       "0  Provide default implementation for `data_repat...   \n",
       "1  Provide default implementation for `data_repat...   \n",
       "2  Provide default implementation for `data_repat...   \n",
       "3  Provide default implementation for `data_repat...   \n",
       "4  Provide default implementation for `data_repat...   \n",
       "\n",
       "                                                diff  \n",
       "0  @@ -31,12 +31,24 @@ def all_data(request, data...  \n",
       "1  @@ -30,14 +30,6 @@ def data_missing():\\n     r...  \n",
       "2  @@ -45,15 +45,6 @@ def data_missing():\\n     r...  \n",
       "3  @@ -47,14 +47,6 @@ def data_missing(dtype):\\n ...  \n",
       "4  @@ -47,15 +47,6 @@ def data_missing():\\n     r...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is a head of df_source dataset\n",
    "df_source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9286, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the size of df_source\n",
    "df_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>file_name</th>\n",
       "      <th>msg</th>\n",
       "      <th>diff</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a277e4aec312abe78689ce361025cd60b25cf0c0</td>\n",
       "      <td>Matthew Roeschke</td>\n",
       "      <td>v0.24.0.txt</td>\n",
       "      <td>BUG: Merge timezone aware data with DST (#22825)</td>\n",
       "      <td>@@ -815,6 +815,7 @@ Reshaping\\n - Bug in :meth...</td>\n",
       "      <td>2018-10-01 05:12:35-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a277e4aec312abe78689ce361025cd60b25cf0c0</td>\n",
       "      <td>Matthew Roeschke</td>\n",
       "      <td>datetimelike.py</td>\n",
       "      <td>BUG: Merge timezone aware data with DST (#22825)</td>\n",
       "      <td>@@ -277,7 +277,7 @@ class DatetimeIndexOpsMixi...</td>\n",
       "      <td>2018-10-01 05:12:35-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a277e4aec312abe78689ce361025cd60b25cf0c0</td>\n",
       "      <td>Matthew Roeschke</td>\n",
       "      <td>test_coercion.py</td>\n",
       "      <td>BUG: Merge timezone aware data with DST (#22825)</td>\n",
       "      <td>@@ -590,11 +590,9 @@ class TestWhereCoercion(C...</td>\n",
       "      <td>2018-10-01 05:12:35-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a277e4aec312abe78689ce361025cd60b25cf0c0</td>\n",
       "      <td>Matthew Roeschke</td>\n",
       "      <td>test_merge.py</td>\n",
       "      <td>BUG: Merge timezone aware data with DST (#22825)</td>\n",
       "      <td>@@ -601,6 +601,30 @@ class TestMerge(object):\\...</td>\n",
       "      <td>2018-10-01 05:12:35-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ce06b5bdb8c44043c6463bf8ce3da758800a189</td>\n",
       "      <td>Matthew Roeschke</td>\n",
       "      <td>v0.24.0.txt</td>\n",
       "      <td>BUG: to_datetime preserves name of Index argum...</td>\n",
       "      <td>@@ -655,6 +655,7 @@ Datetimelike\\n - Bug in :c...</td>\n",
       "      <td>2018-10-01 14:22:20-07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  commit_ID            Author  \\\n",
       "0  a277e4aec312abe78689ce361025cd60b25cf0c0  Matthew Roeschke   \n",
       "1  a277e4aec312abe78689ce361025cd60b25cf0c0  Matthew Roeschke   \n",
       "2  a277e4aec312abe78689ce361025cd60b25cf0c0  Matthew Roeschke   \n",
       "3  a277e4aec312abe78689ce361025cd60b25cf0c0  Matthew Roeschke   \n",
       "4  5ce06b5bdb8c44043c6463bf8ce3da758800a189  Matthew Roeschke   \n",
       "\n",
       "          file_name                                                msg  \\\n",
       "0       v0.24.0.txt   BUG: Merge timezone aware data with DST (#22825)   \n",
       "1   datetimelike.py   BUG: Merge timezone aware data with DST (#22825)   \n",
       "2  test_coercion.py   BUG: Merge timezone aware data with DST (#22825)   \n",
       "3     test_merge.py   BUG: Merge timezone aware data with DST (#22825)   \n",
       "4       v0.24.0.txt  BUG: to_datetime preserves name of Index argum...   \n",
       "\n",
       "                                                diff  \\\n",
       "0  @@ -815,6 +815,7 @@ Reshaping\\n - Bug in :meth...   \n",
       "1  @@ -277,7 +277,7 @@ class DatetimeIndexOpsMixi...   \n",
       "2  @@ -590,11 +590,9 @@ class TestWhereCoercion(C...   \n",
       "3  @@ -601,6 +601,30 @@ class TestMerge(object):\\...   \n",
       "4  @@ -655,6 +655,7 @@ Datetimelike\\n - Bug in :c...   \n",
       "\n",
       "                        Date  \n",
       "0  2018-10-01 05:12:35-07:00  \n",
       "1  2018-10-01 05:12:35-07:00  \n",
       "2  2018-10-01 05:12:35-07:00  \n",
       "3  2018-10-01 05:12:35-07:00  \n",
       "4  2018-10-01 14:22:20-07:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is a head of df_bug dataset\n",
    "df_bug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(843, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the shape of df_bug\n",
    "df_bug.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I check if an author has less than one commit then remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of author in both dataset\n",
    "LDA_code = df_source.groupby(['Author']).size().reset_index(name='count')\n",
    "LDA_bug = df_bug.groupby(['Author']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of commits per author\n",
    "LDA_Author = LDA_code[LDA_code['count']>1]['Author']\n",
    "Final_source = df_source[df_source['Author'].isin(LDA_Author)]\n",
    "Final_source= Final_source[['Author','diff','msg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of commits per author\n",
    "bug_Author = LDA_bug[LDA_bug['count']>1]['Author']\n",
    "Final_bug = df_bug[df_bug['Author'].isin(bug_Author)]\n",
    "Final_bug= Final_bug[['Author','diff','msg']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no author who has less than 2 codes or resolved less than one bug. as you can see the size of data doesnot change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9286, 3)"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(843, 3)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_bug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing dataset for LDA model[removeing extra columns]\n",
    "frames = [Final_source,Final_bug]\n",
    "LDA_result = pd.concat(frames, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>diff</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>@@ -31,12 +31,24 @@ def all_data(request, data...</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>@@ -30,14 +30,6 @@ def data_missing():\\n     r...</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>@@ -45,15 +45,6 @@ def data_missing():\\n     r...</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>@@ -47,14 +47,6 @@ def data_missing(dtype):\\n ...</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>@@ -47,15 +47,6 @@ def data_missing():\\n     r...</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>@@ -202,7 +202,7 @@ def maybe_downcast_numeric...</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>@@ -262,7 +262,7 @@ class SeriesGroupBy(GroupB...</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>@@ -1,3 +1,5 @@\\n+import decimal\\n+\\n import n...</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Joris Van den Bossche</td>\n",
       "      <td>@@ -672,7 +672,13 @@ class BaseGrouper:\\n     ...</td>\n",
       "      <td>BUG/TST: ensure groupby.agg preserves extensio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>Joris Van den Bossche</td>\n",
       "      <td>@@ -426,3 +426,55 @@ def test_array_ufunc_seri...</td>\n",
       "      <td>BUG/TST: ensure groupby.agg preserves extensio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10129 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Author                                               diff  \\\n",
       "0           Tom Augspurger  @@ -31,12 +31,24 @@ def all_data(request, data...   \n",
       "1           Tom Augspurger  @@ -30,14 +30,6 @@ def data_missing():\\n     r...   \n",
       "2           Tom Augspurger  @@ -45,15 +45,6 @@ def data_missing():\\n     r...   \n",
       "3           Tom Augspurger  @@ -47,14 +47,6 @@ def data_missing(dtype):\\n ...   \n",
       "4           Tom Augspurger  @@ -47,15 +47,6 @@ def data_missing():\\n     r...   \n",
       "..                     ...                                                ...   \n",
       "838           jbrockmendel  @@ -202,7 +202,7 @@ def maybe_downcast_numeric...   \n",
       "839           jbrockmendel  @@ -262,7 +262,7 @@ class SeriesGroupBy(GroupB...   \n",
       "840           jbrockmendel  @@ -1,3 +1,5 @@\\n+import decimal\\n+\\n import n...   \n",
       "841  Joris Van den Bossche  @@ -672,7 +672,13 @@ class BaseGrouper:\\n     ...   \n",
       "842  Joris Van den Bossche  @@ -426,3 +426,55 @@ def test_array_ufunc_seri...   \n",
       "\n",
       "                                                   msg  \n",
       "0    Provide default implementation for `data_repat...  \n",
       "1    Provide default implementation for `data_repat...  \n",
       "2    Provide default implementation for `data_repat...  \n",
       "3    Provide default implementation for `data_repat...  \n",
       "4    Provide default implementation for `data_repat...  \n",
       "..                                                 ...  \n",
       "838  BUG: fix TypeError raised in maybe_downcast_nu...  \n",
       "839  BUG: fix TypeError raised in maybe_downcast_nu...  \n",
       "840  BUG: fix TypeError raised in maybe_downcast_nu...  \n",
       "841  BUG/TST: ensure groupby.agg preserves extensio...  \n",
       "842  BUG/TST: ensure groupby.agg preserves extensio...  \n",
       "\n",
       "[10129 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. LDA method on NLP data\n",
    "   * I extract token and calculate the tf-idf of each token with \"TfidfVectorizer()\" which extract tokens within a data and claculate the tf-idf per each token at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an object of tfidfvectorizer with max_dif= 0.95 and min_df =2 \n",
    "#which means those words appear in maximum 95% of data and minimum 2 of data\n",
    "#I consider the source code as an english text file\n",
    "cv_code =  TfidfVectorizer(max_df=0.95, min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we only need the 'diff' column. 'diff' columns contains the content of codes that developer add/remove from main file.\n",
    "LDA_dtm = cv_code.fit_transform(LDA_result['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our LDA model with 10 components (10 topic) and also random seed 42 to keep the result same after rerunning\n",
    "LDA_model = LatentDirichletAllocation(n_components=10,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model with LDA_dtm which contains the tf-idf of each token\n",
    "LDA_model.fit(LDA_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34457"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here is the number of features (tokens)\n",
    "len(cv_code.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 20 WORDS FOR domain #0\n",
      "['copy', 'value', 'str', 'multiindex', 'func', 'false', 'bug', 'method', 'columns', 'dtype', 'def', 'meth', 'data', 'pandas', 'level', 'values', 'raise', 'key', 'dataframe', 'return', 'class', 'series', 'issue', 'index', 'self']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #1\n",
      "['categorical', 'right', 'parametrize', 'categories', 'object', 'idx', 'false', 'class', 'mark', 'result', 'match', 'true', 'expected', 'tm', 'raises', 'pd', 'msg', 'self', 'assert', 'array', 'index', 'def', 'pytest', 'dtype', 'np']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #2\n",
      "['axis', 'class', '10', 'pd', 'frame', 'foo', 'false', 'series', 'pytest', 'true', 'loc', 'assert_frame_equal', 'assert', 'datetime', 'def', 'tm', 'nan', 'self', 'columns', 'np', 'result', 'dataframe', 'expected', 'index', 'df']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #3\n",
      "['2000', 'dtype', 'nan', 'date_range', 'self', 'idx', 'periods', 'exp', '10', 'index', 'def', '2011', 'pytest', 'tz', 'timestamp', 'assert', 'tm', 'np', 'series', 'freq', 'expected', 'result', '00', 'pd', '01']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #4\n",
      "['10', 'version', 'os', 'tslibs', 'stringio', 'com', 'https', 'testing', 'datetime', 'common', 'python', 'data', 'def', 'tests', 'dtypes', 'pytest', 'py', 'io', 'util', '_libs', 'numpy', 'compat', 'core', 'pandas', 'import']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #5\n",
      "['index_col', 'ext', 'true', 'return', 'columns', 'kwds', 'index', 'read_excel', 'tm', 'reference', 'ax', 'fill_value', 'generated', 'data', 'np', 'series', 'api', 'panel', 'pandas', 'false', 'class', 'pd', 'sparse', 'def', 'self']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #6\n",
      "['text', 'right', 'id', 'api', 'table', '15', 'val', '12', 'nonexistent', '10', 'time', '17', 'style', 'int64_t', 'cimport', 'center', '14', 'align', 'generated', 'class', 'autosummary', 'toctree', 'tr', 'th', 'td']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #7\n",
      "['engine', 'pd', 'resample', 'read_csv', 'assert', 'random', 'ax', 'true', 'path', 'pytest', 'store', 'assert_frame_equal', 'parser', '10', 'columns', 'data', 'tm', 'np', 'result', 'def', 'dataframe', 'expected', 'index', 'self', 'df']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #8\n",
      "['copy', 'timedelta', 'format', 'pandas', 'type', 'false', 'assert', 'elif', 'isinstance', 'import', 'cls', 'op', 'values', 'raise', 'arr', 'tz', 'class', 'data', 'np', 'freq', 'result', 'def', 'return', 'dtype', 'self']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #9\n",
      "['func', 'block', 'args', 'ndim', 'mask', 'elif', 'len', 'raise', 'value', 'val', 'ndarray', 'true', 'object', 'false', 'class', 'result', 'kwargs', 'np', 'axis', 'dtype', 'obj', 'def', 'return', 'values', 'self']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Here I preint 25 top words of each topic to show how the LDA model assign the different topic to a group of words. \n",
    "#I consider each topic as a domain in code\n",
    "for index,domain in enumerate(LDA_model.components_):\n",
    "    print(f'THE TOP 20 WORDS FOR domain #{index}')\n",
    "    print([cv_code.get_feature_names()[i] for i in domain.argsort()[-25:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I transform the topics to the model\n",
    "code_domain_results = LDA_model.transform(LDA_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, finally I assign a topic(domain) to each developer\n",
    "LDA_result['domain'] = code_domain_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>diff</th>\n",
       "      <th>msg</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>@@ -31,12 +31,24 @@ def all_data(request, data...</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>@@ -30,14 +30,6 @@ def data_missing():\\n     r...</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>@@ -45,15 +45,6 @@ def data_missing():\\n     r...</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>@@ -47,14 +47,6 @@ def data_missing(dtype):\\n ...</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>@@ -47,15 +47,6 @@ def data_missing():\\n     r...</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>@@ -202,7 +202,7 @@ def maybe_downcast_numeric...</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>@@ -262,7 +262,7 @@ class SeriesGroupBy(GroupB...</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>@@ -1,3 +1,5 @@\\n+import decimal\\n+\\n import n...</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Joris Van den Bossche</td>\n",
       "      <td>@@ -672,7 +672,13 @@ class BaseGrouper:\\n     ...</td>\n",
       "      <td>BUG/TST: ensure groupby.agg preserves extensio...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>Joris Van den Bossche</td>\n",
       "      <td>@@ -426,3 +426,55 @@ def test_array_ufunc_seri...</td>\n",
       "      <td>BUG/TST: ensure groupby.agg preserves extensio...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10129 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Author                                               diff  \\\n",
       "0           Tom Augspurger  @@ -31,12 +31,24 @@ def all_data(request, data...   \n",
       "1           Tom Augspurger  @@ -30,14 +30,6 @@ def data_missing():\\n     r...   \n",
       "2           Tom Augspurger  @@ -45,15 +45,6 @@ def data_missing():\\n     r...   \n",
       "3           Tom Augspurger  @@ -47,14 +47,6 @@ def data_missing(dtype):\\n ...   \n",
       "4           Tom Augspurger  @@ -47,15 +47,6 @@ def data_missing():\\n     r...   \n",
       "..                     ...                                                ...   \n",
       "838           jbrockmendel  @@ -202,7 +202,7 @@ def maybe_downcast_numeric...   \n",
       "839           jbrockmendel  @@ -262,7 +262,7 @@ class SeriesGroupBy(GroupB...   \n",
       "840           jbrockmendel  @@ -1,3 +1,5 @@\\n+import decimal\\n+\\n import n...   \n",
       "841  Joris Van den Bossche  @@ -672,7 +672,13 @@ class BaseGrouper:\\n     ...   \n",
       "842  Joris Van den Bossche  @@ -426,3 +426,55 @@ def test_array_ufunc_seri...   \n",
       "\n",
       "                                                   msg  domain  \n",
       "0    Provide default implementation for `data_repat...       9  \n",
       "1    Provide default implementation for `data_repat...       1  \n",
       "2    Provide default implementation for `data_repat...       1  \n",
       "3    Provide default implementation for `data_repat...       1  \n",
       "4    Provide default implementation for `data_repat...       1  \n",
       "..                                                 ...     ...  \n",
       "838  BUG: fix TypeError raised in maybe_downcast_nu...       8  \n",
       "839  BUG: fix TypeError raised in maybe_downcast_nu...       9  \n",
       "840  BUG: fix TypeError raised in maybe_downcast_nu...       1  \n",
       "841  BUG/TST: ensure groupby.agg preserves extensio...       9  \n",
       "842  BUG/TST: ensure groupby.agg preserves extensio...       2  \n",
       "\n",
       "[10129 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, I extract topics for bugs and source code commits\n",
    "Bug_Result=LDA_result[LDA_result['msg'].str.startswith(\"BUG\")]\n",
    "Source_Result=LDA_result[-LDA_result['msg'].str.startswith(\"BUG\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>diff</th>\n",
       "      <th>msg</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matthew Roeschke</td>\n",
       "      <td>@@ -815,6 +815,7 @@ Reshaping\\n - Bug in :meth...</td>\n",
       "      <td>BUG: Merge timezone aware data with DST (#22825)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matthew Roeschke</td>\n",
       "      <td>@@ -277,7 +277,7 @@ class DatetimeIndexOpsMixi...</td>\n",
       "      <td>BUG: Merge timezone aware data with DST (#22825)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matthew Roeschke</td>\n",
       "      <td>@@ -590,11 +590,9 @@ class TestWhereCoercion(C...</td>\n",
       "      <td>BUG: Merge timezone aware data with DST (#22825)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matthew Roeschke</td>\n",
       "      <td>@@ -601,6 +601,30 @@ class TestMerge(object):\\...</td>\n",
       "      <td>BUG: Merge timezone aware data with DST (#22825)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matthew Roeschke</td>\n",
       "      <td>@@ -655,6 +655,7 @@ Datetimelike\\n - Bug in :c...</td>\n",
       "      <td>BUG: to_datetime preserves name of Index argum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>@@ -202,7 +202,7 @@ def maybe_downcast_numeric...</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>@@ -262,7 +262,7 @@ class SeriesGroupBy(GroupB...</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>@@ -1,3 +1,5 @@\\n+import decimal\\n+\\n import n...</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Joris Van den Bossche</td>\n",
       "      <td>@@ -672,7 +672,13 @@ class BaseGrouper:\\n     ...</td>\n",
       "      <td>BUG/TST: ensure groupby.agg preserves extensio...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>Joris Van den Bossche</td>\n",
       "      <td>@@ -426,3 +426,55 @@ def test_array_ufunc_seri...</td>\n",
       "      <td>BUG/TST: ensure groupby.agg preserves extensio...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>843 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Author                                               diff  \\\n",
       "0         Matthew Roeschke  @@ -815,6 +815,7 @@ Reshaping\\n - Bug in :meth...   \n",
       "1         Matthew Roeschke  @@ -277,7 +277,7 @@ class DatetimeIndexOpsMixi...   \n",
       "2         Matthew Roeschke  @@ -590,11 +590,9 @@ class TestWhereCoercion(C...   \n",
       "3         Matthew Roeschke  @@ -601,6 +601,30 @@ class TestMerge(object):\\...   \n",
       "4         Matthew Roeschke  @@ -655,6 +655,7 @@ Datetimelike\\n - Bug in :c...   \n",
       "..                     ...                                                ...   \n",
       "838           jbrockmendel  @@ -202,7 +202,7 @@ def maybe_downcast_numeric...   \n",
       "839           jbrockmendel  @@ -262,7 +262,7 @@ class SeriesGroupBy(GroupB...   \n",
       "840           jbrockmendel  @@ -1,3 +1,5 @@\\n+import decimal\\n+\\n import n...   \n",
       "841  Joris Van den Bossche  @@ -672,7 +672,13 @@ class BaseGrouper:\\n     ...   \n",
       "842  Joris Van den Bossche  @@ -426,3 +426,55 @@ def test_array_ufunc_seri...   \n",
       "\n",
       "                                                   msg  domain  \n",
       "0     BUG: Merge timezone aware data with DST (#22825)       0  \n",
       "1     BUG: Merge timezone aware data with DST (#22825)       8  \n",
       "2     BUG: Merge timezone aware data with DST (#22825)       3  \n",
       "3     BUG: Merge timezone aware data with DST (#22825)       3  \n",
       "4    BUG: to_datetime preserves name of Index argum...       0  \n",
       "..                                                 ...     ...  \n",
       "838  BUG: fix TypeError raised in maybe_downcast_nu...       8  \n",
       "839  BUG: fix TypeError raised in maybe_downcast_nu...       9  \n",
       "840  BUG: fix TypeError raised in maybe_downcast_nu...       1  \n",
       "841  BUG/TST: ensure groupby.agg preserves extensio...       9  \n",
       "842  BUG/TST: ensure groupby.agg preserves extensio...       2  \n",
       "\n",
       "[843 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bug_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I extract only two column of source code result which is author and domain.\n",
    "#becuase after assigning a domain to each developer and also assign a domain to each bug, we don't need their code anymore(becuase we already know their domains)\n",
    "Author_Domain=Source_Result[['Author','domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9281</th>\n",
       "      <td>William Ayd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9282</th>\n",
       "      <td>William Ayd</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9283</th>\n",
       "      <td>William Ayd</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9284</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9286 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Author  domain\n",
       "0     Tom Augspurger       9\n",
       "1     Tom Augspurger       1\n",
       "2     Tom Augspurger       1\n",
       "3     Tom Augspurger       1\n",
       "4     Tom Augspurger       1\n",
       "...              ...     ...\n",
       "9281     William Ayd       0\n",
       "9282     William Ayd       9\n",
       "9283     William Ayd       2\n",
       "9284    jbrockmendel       7\n",
       "9285    jbrockmendel       7\n",
       "\n",
       "[9286 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Author_Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the topest domain of each developer, we count the number of commits in each topic per developer\n",
    "Author_groupby=Author_Domain.groupby(['Author','domain']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>domain</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Christopher Whelan</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Christopher Whelan</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christopher Whelan</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christopher Whelan</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christopher Whelan</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>8</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>9</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Author  domain  count\n",
       "0    Christopher Whelan       0     20\n",
       "1    Christopher Whelan       1     10\n",
       "2    Christopher Whelan       2      1\n",
       "3    Christopher Whelan       3      3\n",
       "4    Christopher Whelan       4      7\n",
       "..                  ...     ...    ...\n",
       "138        jbrockmendel       5     46\n",
       "139        jbrockmendel       6     58\n",
       "140        jbrockmendel       7     41\n",
       "141        jbrockmendel       8    612\n",
       "142        jbrockmendel       9    413\n",
       "\n",
       "[143 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Author_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I find the top1, 3 topest and 5 topest topic per developer\n",
    "Top_1_domain=Author_groupby.groupby(['Author'])['domain','count'].apply(lambda x: x.nlargest(2,columns=['count'])).reset_index()\n",
    "Top_3_domain=Author_groupby.groupby(['Author'])['domain','count'].apply(lambda x: x.nlargest(3,columns=['count'])).reset_index()\n",
    "Top_5_domain=Author_groupby.groupby(['Author'])['domain','count'].apply(lambda x: x.nlargest(5,columns=['count'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1_Au_domain = Top_1_domain[['Author','domain']]\n",
    "top_3_Au_domain = Top_3_domain[['Author','domain']]\n",
    "top_5_Au_domain = Top_5_domain[['Author','domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I join the top 1, 3 topest and 5topest domains per developer with Bug_result dataset to find that \n",
    "#if the domain of bug_x is domain_A and developer who solve bug_x is dev_Y, dev_Y has domain_A as top1, 3 topest or 5topest topics or not?\n",
    "Top_1_Prediction=pd.merge(Bug_Result, top_1_Au_domain, on='Author')\n",
    "Top_3_Prediction=pd.merge(Bug_Result, top_3_Au_domain, on='Author')\n",
    "Top_5_Prediction=pd.merge(Bug_Result, top_5_Au_domain, on='Author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top_1_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I calculate the accuracy which is the number of time we predict the currect developer (based on a domain) to solve a bug\n",
    "Accuracy_at_top1=(len(Top_1_Prediction[(Top_1_Prediction['domain_x']==Top_1_Prediction['domain_y'])])/len(Bug_Result))*100\n",
    "Accuracy_at_top3=(len(Top_3_Prediction[(Top_3_Prediction['domain_x']==Top_3_Prediction['domain_y'])])/len(Bug_Result))*100\n",
    "Accuracy_at_top5=(len(Top_5_Prediction[(Top_5_Prediction['domain_x']==Top_5_Prediction['domain_y'])])/len(Bug_Result))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy @ Top 1 Domian: 31.079478054567023\n",
      "Accuracy @ Top 3 Domian: 45.78884934756821\n",
      "Accuracy @ Top 5 Domian: 75.68208778173191\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy @ Top 1 Domian:\" , Accuracy_at_top1)\n",
    "print(\"Accuracy @ Top 3 Domian:\" , Accuracy_at_top3)\n",
    "print(\"Accuracy @ Top 5 Domian:\" , Accuracy_at_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. KNN method on NLP data\n",
    "** \n",
    "As a result of LDA in \"NLP\" dataset, I get the 75.68% accuracy while considering top 5 domain per each developer.\n",
    "It is obvious that when we increase the number of domains the accuracy increase too. becuase the chance of finding the domain of bug in domain of developer is increased.\n",
    "But in continue, I use a classification method (KNN) as a baseline to compare its result with LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an object of tfidfvectorizer and KNN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing data into testset and trainset. but as we want to predict the developer of bugs, we already have our testset which is bug dataset\n",
    "X_train = Final_source['diff']\n",
    "#We consider author name as a label\n",
    "Y_train = Final_source['Author']\n",
    "X_test = Final_bug['diff']\n",
    "Y_test = Final_bug['Author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9286, 56236)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating tokens and tfidf on trainset data\n",
    "NLP_tfidf_transformer = TfidfVectorizer()\n",
    "NLP_X_train_tfidf = NLP_tfidf_transformer.fit_transform(X_train)\n",
    "NLP_X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(843, 56236)"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create tokens and its tfidf on testset data\n",
    "NLP_X_test_tfidf = NLP_tfidf_transformer.transform(X_test)\n",
    "NLP_X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the range of neighbors\n",
    "k_range = range(1,6)\n",
    "NLP_score=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in 1 neighbor is: 44.72123368920522\n",
      "The accuracy in 2 neighbor is: 29.418742586002374\n",
      "The accuracy in 3 neighbor is: 31.791221826809014\n",
      "The accuracy in 4 neighbor is: 22.65717674970344\n",
      "The accuracy in 5 neighbor is: 21.11506524317912\n"
     ]
    }
   ],
   "source": [
    "#loop for different number of neighbors and calculate the accuracy of model in each number of neighbors\n",
    "for k in k_range:\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(NLP_X_train_tfidf,Y_train)\n",
    "    NLP_y_predict = knn.predict(NLP_X_test_tfidf)\n",
    "    score= accuracy_score(Y_test, NLP_y_predict)*100\n",
    "    NLP_score.append(score)\n",
    "    print(\"The accuracy in {} neighbor is: {}\".format(k, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that LDA method on \"NLP\" dataset has a better accuracy than baseline model KNN. The reason is KNN is a classification model and needs more distinguished tokens (features) to be abale to classify developers correctly. \n",
    "In the other word, our main target was defining the domains of code for each developer and not classification of developers. And to define the domain based on a content topic modeling algorithms are a better choise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. extracting data for AST study\n",
    " * To continue the project, as I explained above, we try to extract tokens from AST (nodes of the tree) which is a better (more accurate) reflection of developers expertise.\n",
    " * To extract the tokens of each commits by AST, I extract the AST of a source code before commit and a AST of a source code after commit and then find the difference between tokens of these two files. It is a better reflection of what a developer did semantically in a code. becuase sometime a developer removes a function within a code and then paste the same function and only delete the spaces between two lines. if we check 'diff' file for this commit, it contains all removed and added lines while the developer doesn't do any real developing action.\n",
    "But when we compare the AST of code before and after commit, we will find the real change and in above sample the difference of AST between two codes returns nothing (empty string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenize\n",
    "import pydriller as cm_pyd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am downloading the same dataset with the same method but this time instead of 'diff', I am downloading 'commit_before' and 'commit_after'. (for the same duration and same developer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dt1 = datetime(2018, 1, 1)\n",
    "tf_dt2 = datetime(2019, 10, 31)\n",
    "tf_source = pd.DataFrame(columns=['commit_ID', 'Author','msg', 'Commit_before', 'Commit_after'])\n",
    "tf_bug = pd.DataFrame(columns=['commit_ID', 'Author','msg', 'Commit_before', 'Commit_after'])\n",
    "path = \"https://github.com/pandas-dev/pandas.git\"\n",
    "Authors = ['Jeff Reback','jbrockmendel','Joris Van den Bossche','Tom Augspurger','gfyoung','Matthew Roeschke',\n",
    "           'Terji Petersen','William Ayd','Simon Hawkins','Jeremy Schendel','Marc Garcia',\n",
    "           'Pietro Battiston','h-vetinari','Christopher Whelan','alimcmaster1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Please be informed that below function takes time around 45 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <finalize object at 0x1ad96fd04e0; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\weakref.py\", line 552, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\tempfile.py\", line 795, in _cleanup\n",
      "    _shutil.rmtree(name)\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 513, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 392, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 392, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 392, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 397, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"c:\\users\\morad\\anaconda3\\lib\\shutil.py\", line 395, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\morad\\\\AppData\\\\Local\\\\Temp\\\\tmpsd5vc2z0\\\\pandas\\\\.git\\\\objects\\\\pack\\\\pack-803a8fe7172e34473152b94e00a7d0fb8ab7b537.idx'\n"
     ]
    }
   ],
   "source": [
    "for commit in cm_pyd.RepositoryMining(path_to_repo=path, since=tf_dt1, to=tf_dt2, only_authors=Authors).traverse_commits():\n",
    "    for modified_file in commit.modifications:\n",
    "        if modified_file.filename.endswith(\".py\"):\n",
    "            if commit.msg.startswith(\"BUG\"):\n",
    "                tf_bug = tf_bug.append({'commit_ID': commit.hash, 'Author': commit.author.name,\n",
    "                                        'msg': commit.msg,'Commit_before': modified_file.source_code_before,\n",
    "                                        'Commit_after': modified_file.source_code}, ignore_index=True)\n",
    "                #print(\"BUG\", commit.hash, commit.author.name, commit.author_date,commit.msg,\n",
    "                                           #modified_file.filename, flush=True)\n",
    "            else:\n",
    "                tf_source = tf_source.append({'commit_ID': commit.hash, 'Author': commit.author.name,\n",
    "                                        'msg': commit.msg,'Commit_before': modified_file.source_code_before,\n",
    "                                        'Commit_after': modified_file.source_code}, ignore_index=True)\n",
    "                #print(\"Code\", commit.hash, commit.author.name, commit.msg,commit.author_date,\n",
    "                        # modified_file.filename, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data into csv file\n",
    "tf_source.to_csv(r'C:\\GH-Dataset\\source_before_after.csv', index=None, header=True)\n",
    "tf_bug.to_csv(r'C:\\GH-Dataset\\bug_before_after.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I write a function to extract the node's name in AST by walking through the tree and visiting each node's class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuncParser(ast.NodeVisitor):\n",
    "    def visit_Load(self, node): pass\n",
    "    def visit_Store(self, node): pass\n",
    "    def visit_NameConstant(self,node):pass\n",
    "    def visit_Str(self, node): \n",
    "        file_contents.append(node.__class__.__name__) \n",
    "    def visit_Num(self, node):\n",
    "        file_contents.append(node.__class__.__name__)\n",
    "    def visit_Module(self, node): \n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_keyword(self,node):\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_arguments(self, node): \n",
    "        if(node.kwonlyargs == []):\n",
    "                file_contents.append(\"arguments: Standard\")\n",
    "        elif (node.kw_defaults==[]):\n",
    "            file_contents.append(\"arguments: kwonlyargs\")\n",
    "        else:\n",
    "            file_contents.append(\"arguments: Arbitraryargs\")\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_Expr(self, node): \n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_Assign(self, node): \n",
    "       # if(node.value != None):\n",
    "            # file_contents.append([\"Assign:\"+node.value.__class__.__name__])\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_Compare(self,node):\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_AugAssign(self,node):\n",
    "        temp = (node.op)\n",
    "        oper= \"AugAssign: \" + temp.__class__.__name__ +\"()\"\n",
    "        file_contents.append(oper)\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_Subscript(self,node):\n",
    "        index = node.slice\n",
    "        if(index.__class__.__name__ == 'Index'):\n",
    "            slc = index.value\n",
    "            if(slc.__class__.__name__ == 'Num'):\n",
    "                file_contents.append(\"Subscript:Index[Num]\")\n",
    "            elif(slc.__class__.__name__ == 'UnaryOp'):\n",
    "                operand = slc.op\n",
    "                file_contents.append(\"Subscript:Index[UnaryOp:\"+operand.__class__.__name__+\"]\") \n",
    "            elif(slc.__class__.__name__ == 'Name'):\n",
    "                file_contents.append(\"Subscript:Index[Var]\")\n",
    "        else:\n",
    "            file_contents.append(\"Subscript:Index[\"+index.__class__.__name__+\"]\")\n",
    "            \n",
    "            #ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_If(self,node):\n",
    "        file_contents.append(node.__class__.__name__)\n",
    "        if(node.orelse == []):\n",
    "            ast.NodeVisitor.generic_visit(self, node)\n",
    "        else:\n",
    "            file_contents.append(\"orelse\")\n",
    "            ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_FunctionDef(self,node):\n",
    "        file_contents.append(\"FunctionDef\")\n",
    "        #file_contents.append([node.name])\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_ClassDef(self,node):\n",
    "        baselist= node.bases\n",
    "        if(len(baselist)==0):\n",
    "            file_contents.append(\"ClassDef: Simple\")\n",
    "            ast.NodeVisitor.generic_visit(self, node)\n",
    "        elif(len(baselist)==1):\n",
    "            file_contents.append(\"ClassDef: Inherit\")\n",
    "            ast.NodeVisitor.generic_visit(self, node)\n",
    "        elif(len(baselist)>1):\n",
    "            file_contents.append(\"ClassDef: MultiInherit\")\n",
    "            ast.NodeVisitor.generic_visit(self, node)     \n",
    "    def visit_Call(self, node): \n",
    "        #file_contents.append(\"FuncCall\")\n",
    "        #ast.NodeVisitor.generic_visit(self, node)\n",
    "        attrib = node.func\n",
    "        if(attrib.__class__.__name__ == 'Attribute'):\n",
    "            file_contents.append(attrib.attr)\n",
    "            ast.NodeVisitor.generic_visit(self, node)\n",
    "        elif (attrib.__class__.__name__ == 'Name'):\n",
    "            file_contents.append(attrib.id)\n",
    "            #file_contents.append([attrib.id])\n",
    "            ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_arg(self, node): \n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_BinOp(self,node):\n",
    "        #temp = (node.op)\n",
    "        #op = \"BinOp: \"+temp.__class__.__name__ +\"()\"\n",
    "        #file_contents.append(op)\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_Import(self, node): \n",
    "        tempImpo = node.names\n",
    "        if(tempImpo != None):\n",
    "            listImpo = tempImpo[0]\n",
    "            Impo = listImpo.name\n",
    "            file_contents.append(\"Import\")\n",
    "            file_contents.append(Impo)\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_ImportFrom(self, node):\n",
    "        module=node.module\n",
    "        file_contents.append(\"ImportFrom\")\n",
    "        file_contents.append(module)\n",
    "        #if(node.module != None):\n",
    "           # n3= (node.module)\n",
    "           # file_contents.append(\"ImportFrom:\" + n3)\n",
    "       # else:\n",
    "            #file_contents.append(node.__class__.__name__)\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_alias(self, node): \n",
    "        #n1 =  (node.name)\n",
    "        #file_contents.append(n1)\n",
    "        #if(node.asname != None):\n",
    "            #n2 =  (node.asname)\n",
    "            #file_contents.append([n2])\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_Name(self, node):\n",
    "       # temp =\"Name:\"+node.id\n",
    "        #file_contents.append([node.id])\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_comprehension(self,node):\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def visit_Attribute(self, node): \n",
    "        temp1 =\"Name:\"+node.attr\n",
    "        file_contents.append(node.attr)\n",
    "        ast.NodeVisitor.generic_visit(self, node)\n",
    "    def generic_visit(self, node):\n",
    "        file_contents.append(node.__class__.__name__)\n",
    "        #for f in node._fields:\n",
    "           # if(not f in stop_word):     \n",
    "              #  file_contents.append([f])\n",
    "        #ast.iter_fields(node)\n",
    "        ast.NodeVisitor.generic_visit(self, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_source =  pd.read_csv('C:\\GH-Dataset\\GH_Data_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heap_Dev = Final_source.loc[Final_source['Author'] == 'topper-123']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-5d07ac628737>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mHeap_Dev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHeap_Dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Commit_before'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "for row in Heap_Dev.iterrows():\n",
    "    print(Heap_Dev['Commit_before'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. a step by step explanation of how AST function works and find the tokens: in below, I show for one sample how I extract the difference token between 'before-commit' and 'after-commit'. Then I wrote a function loop which loops in all dataset to extract the difference tokens per each commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b018c04eed15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#First we need to put the 'commit_before' and 'commit_after' into two different text file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#becuase AST accept a string which is a read line by line of a code file. but while we store the commit in a cell of dataframe, it is not able to be read line by line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtext_before\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHeap_Dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Commit_before'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtext_after\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHeap_Dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Commit_after'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbefore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"before-commit.py\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w+\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4729\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4730\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4731\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4732\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "#First we need to put the 'commit_before' and 'commit_after' into two different text file\n",
    "#becuase AST accept a string which is a read line by line of a code file. but while we store the commit in a cell of dataframe, it is not able to be read line by line\n",
    "text_before=Heap_Dev['Commit_before'][1]\n",
    "text_after=Heap_Dev['Commit_after'][1]\n",
    "before = open(\"before-commit.py\", \"w+\")\n",
    "after = open(\"after-commit.py\", \"w+\")\n",
    "before.write(text_before)\n",
    "after.write(text_after)\n",
    "#before.closed()\n",
    "#after.closed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we open the 'commit-before' file read it and call \"FuncParser\" which is a function I wrote above to visit the nodes of AST. then I print all tokens of 'before-commit' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tokenize.open(\"before-commit.py\") as sf:  # need the tokenize.open for source files and not a string\n",
    "    source_file_before = sf.read()\n",
    "\n",
    "ast_before = ast.parse(source_file_before)\n",
    "bf_obj = FuncParser()\n",
    "bf_tree = ast.parse(ast_before)\n",
    "file_contents = []\n",
    "bf_obj.visit(bf_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Import:decimal'],\n",
       " ['Import:random'],\n",
       " ['Import:numpy'],\n",
       " ['ImportFrom:np'],\n",
       " ['Import:pandas'],\n",
       " ['ImportFrom:pd'],\n",
       " ['Import:pandas.util.testing'],\n",
       " ['ImportFrom:tm'],\n",
       " ['Import:pytest'],\n",
       " ['ImportFrom:pandas.tests.extension'],\n",
       " ['Import:base'],\n",
       " ['ImportFrom:array'],\n",
       " ['Import:DecimalDtype'],\n",
       " ['Import:DecimalArray'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Return'],\n",
       " ['ListComp'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Call'],\n",
       " ['random'],\n",
       " ['Name:random'],\n",
       " ['comprehension'],\n",
       " ['Name:_'],\n",
       " ['Call'],\n",
       " ['Name:range'],\n",
       " ['Num'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Return'],\n",
       " ['Call'],\n",
       " ['Name:DecimalDtype'],\n",
       " ['fixture'],\n",
       " ['Name:pytest'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Return'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['Call'],\n",
       " ['Name:make_data'],\n",
       " ['fixture'],\n",
       " ['Name:pytest'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Return'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['List'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Num'],\n",
       " ['fixture'],\n",
       " ['Name:pytest'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:count'],\n",
       " ['For'],\n",
       " ['Name:_'],\n",
       " ['Call'],\n",
       " ['Name:range'],\n",
       " ['Name:count'],\n",
       " ['Yield'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['Call'],\n",
       " ['Name:make_data'],\n",
       " ['Yield'],\n",
       " ['Name:gen'],\n",
       " ['fixture'],\n",
       " ['Name:pytest'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Return'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['List'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['fixture'],\n",
       " ['Name:pytest'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Return'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['List'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['fixture'],\n",
       " ['Name:pytest'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Return'],\n",
       " ['Lambda'],\n",
       " ['arguments'],\n",
       " ['arg:x'],\n",
       " ['arg:y'],\n",
       " ['BoolOp: And()'],\n",
       " ['And'],\n",
       " ['Call'],\n",
       " ['is_nan'],\n",
       " ['Name:x'],\n",
       " ['Call'],\n",
       " ['is_nan'],\n",
       " ['Name:y'],\n",
       " ['fixture'],\n",
       " ['Name:pytest'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Return'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['fixture'],\n",
       " ['Name:pytest'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Name:b'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Name:a'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Name:c'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Name:na'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Return'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['List'],\n",
       " ['Name:b'],\n",
       " ['Name:b'],\n",
       " ['Name:na'],\n",
       " ['Name:na'],\n",
       " ['Name:a'],\n",
       " ['Name:a'],\n",
       " ['Name:b'],\n",
       " ['Name:c'],\n",
       " ['fixture'],\n",
       " ['Name:pytest'],\n",
       " ['ClassDef'],\n",
       " ['Name:object'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:left'],\n",
       " ['arg:right'],\n",
       " ['arg:args'],\n",
       " ['arg:kwargs'],\n",
       " ['Name:left_na'],\n",
       " ['Call'],\n",
       " ['isna'],\n",
       " ['Name:left'],\n",
       " ['Name:right_na'],\n",
       " ['Call'],\n",
       " ['isna'],\n",
       " ['Name:right'],\n",
       " ['Call'],\n",
       " ['assert_series_equal'],\n",
       " ['Name:tm'],\n",
       " ['Name:left_na'],\n",
       " ['Name:right_na'],\n",
       " ['Return'],\n",
       " ['Call'],\n",
       " ['assert_series_equal'],\n",
       " ['Name:tm'],\n",
       " ['Subscript'],\n",
       " ['Name:left'],\n",
       " ['Index'],\n",
       " ['UnaryOp'],\n",
       " ['Invert'],\n",
       " ['Name:left_na'],\n",
       " ['Subscript'],\n",
       " ['Name:right'],\n",
       " ['Index'],\n",
       " ['UnaryOp'],\n",
       " ['Invert'],\n",
       " ['Name:right_na'],\n",
       " ['Starred'],\n",
       " ['Name:args'],\n",
       " [None],\n",
       " ['Name:kwargs'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:left'],\n",
       " ['arg:right'],\n",
       " ['arg:args'],\n",
       " ['arg:kwargs'],\n",
       " ['Call'],\n",
       " ['assert_index_equal'],\n",
       " ['Name:tm'],\n",
       " ['columns'],\n",
       " ['Name:left'],\n",
       " ['columns'],\n",
       " ['Name:right'],\n",
       " ['exact'],\n",
       " ['Call'],\n",
       " ['get'],\n",
       " ['Name:kwargs'],\n",
       " ['Str'],\n",
       " ['Str'],\n",
       " ['check_names'],\n",
       " ['Call'],\n",
       " ['get'],\n",
       " ['Name:kwargs'],\n",
       " ['Str'],\n",
       " ['NameConstant'],\n",
       " ['check_exact'],\n",
       " ['Call'],\n",
       " ['get'],\n",
       " ['Name:kwargs'],\n",
       " ['Str'],\n",
       " ['NameConstant'],\n",
       " ['check_categorical'],\n",
       " ['Call'],\n",
       " ['get'],\n",
       " ['Name:kwargs'],\n",
       " ['Str'],\n",
       " ['NameConstant'],\n",
       " ['obj'],\n",
       " ['Call'],\n",
       " ['format'],\n",
       " ['Str'],\n",
       " ['obj'],\n",
       " ['Call'],\n",
       " ['get'],\n",
       " ['Name:kwargs'],\n",
       " ['Str'],\n",
       " ['Str'],\n",
       " ['Name:decimals'],\n",
       " ['index'],\n",
       " ['Compare'],\n",
       " ['dtypes'],\n",
       " ['Name:left'],\n",
       " ['Eq'],\n",
       " ['Str'],\n",
       " ['For'],\n",
       " ['Name:col'],\n",
       " ['Name:decimals'],\n",
       " ['Call'],\n",
       " ['assert_series_equal'],\n",
       " ['Name:self'],\n",
       " ['Subscript'],\n",
       " ['Name:left'],\n",
       " ['Index'],\n",
       " ['Name:col'],\n",
       " ['Subscript'],\n",
       " ['Name:right'],\n",
       " ['Index'],\n",
       " ['Name:col'],\n",
       " ['Starred'],\n",
       " ['Name:args'],\n",
       " [None],\n",
       " ['Name:kwargs'],\n",
       " ['Name:left'],\n",
       " ['Call'],\n",
       " ['drop'],\n",
       " ['Name:left'],\n",
       " ['columns'],\n",
       " ['Name:decimals'],\n",
       " ['Name:right'],\n",
       " ['Call'],\n",
       " ['drop'],\n",
       " ['Name:right'],\n",
       " ['columns'],\n",
       " ['Name:decimals'],\n",
       " ['Call'],\n",
       " ['assert_frame_equal'],\n",
       " ['Name:tm'],\n",
       " ['Name:left'],\n",
       " ['Name:right'],\n",
       " ['Starred'],\n",
       " ['Name:args'],\n",
       " [None],\n",
       " ['Name:kwargs'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseDtypeTests'],\n",
       " ['Name:base'],\n",
       " ['Pass'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseInterfaceTests'],\n",
       " ['Name:base'],\n",
       " ['Pass'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseConstructorsTests'],\n",
       " ['Name:base'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:data'],\n",
       " ['Pass'],\n",
       " ['Call'],\n",
       " ['xfail'],\n",
       " ['mark'],\n",
       " ['Name:pytest'],\n",
       " ['reason'],\n",
       " ['Str'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseReshapingTests'],\n",
       " ['Name:base'],\n",
       " ['Pass'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseGetitemTests'],\n",
       " ['Name:base'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['Name:arr'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['List'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Name:result'],\n",
       " ['Call'],\n",
       " ['take'],\n",
       " ['Name:arr'],\n",
       " ['List'],\n",
       " ['Num'],\n",
       " ['UnaryOp'],\n",
       " ['USub'],\n",
       " ['Num'],\n",
       " ['allow_fill'],\n",
       " ['NameConstant'],\n",
       " ['fill_value'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Name:expected'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['List'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Call'],\n",
       " ['assert_extension_array_equal'],\n",
       " ['Name:self'],\n",
       " ['Name:result'],\n",
       " ['Name:expected'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseMissingTests'],\n",
       " ['Name:base'],\n",
       " ['Pass'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseMethodsTests'],\n",
       " ['Name:base'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:all_data'],\n",
       " ['arg:dropna'],\n",
       " ['Name:all_data'],\n",
       " ['Subscript'],\n",
       " ['Name:all_data'],\n",
       " ['Slice'],\n",
       " ['Num'],\n",
       " ['If'],\n",
       " ['Name:dropna'],\n",
       " ['Name:other'],\n",
       " ['Call'],\n",
       " ['array'],\n",
       " ['Name:np'],\n",
       " ['Subscript'],\n",
       " ['Name:all_data'],\n",
       " ['Index'],\n",
       " ['UnaryOp'],\n",
       " ['Invert'],\n",
       " ['Call'],\n",
       " ['isna'],\n",
       " ['Name:all_data'],\n",
       " ['Name:other'],\n",
       " ['Name:all_data'],\n",
       " ['Name:result'],\n",
       " ['Call'],\n",
       " ['sort_index'],\n",
       " ['Call'],\n",
       " ['value_counts'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['Name:all_data'],\n",
       " ['dropna'],\n",
       " ['Name:dropna'],\n",
       " ['Name:expected'],\n",
       " ['Call'],\n",
       " ['sort_index'],\n",
       " ['Call'],\n",
       " ['value_counts'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['Name:other'],\n",
       " ['dropna'],\n",
       " ['Name:dropna'],\n",
       " ['Call'],\n",
       " ['assert_series_equal'],\n",
       " ['Name:tm'],\n",
       " ['Name:result'],\n",
       " ['Name:expected'],\n",
       " ['Call'],\n",
       " ['parametrize'],\n",
       " ['mark'],\n",
       " ['Name:pytest'],\n",
       " ['Str'],\n",
       " ['List'],\n",
       " ['NameConstant'],\n",
       " ['NameConstant'],\n",
       " ['Call'],\n",
       " ['xfail'],\n",
       " ['mark'],\n",
       " ['Name:pytest'],\n",
       " ['reason'],\n",
       " ['Str'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseCastingTests'],\n",
       " ['Name:base'],\n",
       " ['Pass'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseGroupbyTests'],\n",
       " ['Name:base'],\n",
       " ['Pass'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseSetitemTests'],\n",
       " ['Name:base'],\n",
       " ['Pass'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Name:xpr'],\n",
       " ['Str'],\n",
       " ['With'],\n",
       " ['withitem'],\n",
       " ['Call'],\n",
       " ['assert_raises_regex'],\n",
       " ['Name:tm'],\n",
       " ['Name:ValueError'],\n",
       " ['Name:xpr'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['List'],\n",
       " ['Num'],\n",
       " ['Num'],\n",
       " ['Num'],\n",
       " ['dtype'],\n",
       " ['Call'],\n",
       " ['Name:DecimalDtype'],\n",
       " ['Call'],\n",
       " ['xfail'],\n",
       " ['mark'],\n",
       " ['Name:pytest'],\n",
       " ['reason'],\n",
       " ['Str'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Name:arr'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['List'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Name:result'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['Name:arr'],\n",
       " ['dtype'],\n",
       " ['Call'],\n",
       " ['Name:DecimalDtype'],\n",
       " ['Name:expected'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['Name:arr'],\n",
       " ['Call'],\n",
       " ['assert_series_equal'],\n",
       " ['Name:tm'],\n",
       " ['Name:result'],\n",
       " ['Name:expected'],\n",
       " ['Name:result'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['Name:arr'],\n",
       " ['dtype'],\n",
       " ['Str'],\n",
       " ['Name:expected'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['List'],\n",
       " ['Num'],\n",
       " ['Call'],\n",
       " ['assert_series_equal'],\n",
       " ['Name:tm'],\n",
       " ['Name:result'],\n",
       " ['Name:expected'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['Name:arr'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['List'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Name:result'],\n",
       " ['Call'],\n",
       " ['DataFrame'],\n",
       " ['Name:pd'],\n",
       " ['Dict'],\n",
       " ['Str'],\n",
       " ['Name:arr'],\n",
       " ['dtype'],\n",
       " ['Call'],\n",
       " ['Name:DecimalDtype'],\n",
       " ['Name:expected'],\n",
       " ['Call'],\n",
       " ['DataFrame'],\n",
       " ['Name:pd'],\n",
       " ['Dict'],\n",
       " ['Str'],\n",
       " ['Name:arr'],\n",
       " ['Call'],\n",
       " ['assert_frame_equal'],\n",
       " ['Name:tm'],\n",
       " ['Name:result'],\n",
       " ['Name:expected'],\n",
       " ['Name:arr'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['List'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Str'],\n",
       " ['Name:result'],\n",
       " ['Call'],\n",
       " ['DataFrame'],\n",
       " ['Name:pd'],\n",
       " ['Dict'],\n",
       " ['Str'],\n",
       " ['Name:arr'],\n",
       " ['dtype'],\n",
       " ['Str'],\n",
       " ['Name:expected'],\n",
       " ['Call'],\n",
       " ['DataFrame'],\n",
       " ['Name:pd'],\n",
       " ['Dict'],\n",
       " ['Str'],\n",
       " ['List'],\n",
       " ['Num'],\n",
       " ['Call'],\n",
       " ['assert_frame_equal'],\n",
       " ['Name:tm'],\n",
       " ['Name:result'],\n",
       " ['Name:expected'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:frame'],\n",
       " ['Name:data'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['Call'],\n",
       " ['Name:DecimalArray'],\n",
       " ['List'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Num'],\n",
       " ['name'],\n",
       " ['Str'],\n",
       " ['Name:ctx'],\n",
       " ['Call'],\n",
       " ['Context'],\n",
       " ['Name:decimal'],\n",
       " ['prec'],\n",
       " ['Name:ctx'],\n",
       " ['Num'],\n",
       " ['If'],\n",
       " ['Name:frame'],\n",
       " ['Name:data'],\n",
       " ['Call'],\n",
       " ['to_frame'],\n",
       " ['Name:data'],\n",
       " ['Name:result'],\n",
       " ['Call'],\n",
       " ['astype'],\n",
       " ['Name:data'],\n",
       " ['Call'],\n",
       " ['Name:DecimalDtype'],\n",
       " ['Name:ctx'],\n",
       " ['If'],\n",
       " ['Name:frame'],\n",
       " ['Name:result'],\n",
       " ['Subscript'],\n",
       " ['Name:result'],\n",
       " ['Index'],\n",
       " ['Str'],\n",
       " ['Assert'],\n",
       " ['Compare'],\n",
       " ['prec'],\n",
       " ['context'],\n",
       " ['dtype'],\n",
       " ['Name:result'],\n",
       " ['Eq'],\n",
       " ['prec'],\n",
       " ['Name:ctx'],\n",
       " ['Call'],\n",
       " ['parametrize'],\n",
       " ['mark'],\n",
       " ['Name:pytest'],\n",
       " ['Str'],\n",
       " ['List'],\n",
       " ['NameConstant'],\n",
       " ['NameConstant'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseArithmeticOpsTests'],\n",
       " ['Name:base'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:s'],\n",
       " ['arg:op_name'],\n",
       " ['arg:other'],\n",
       " ['arg:exc'],\n",
       " ['NameConstant'],\n",
       " ['Call'],\n",
       " ['check_opname'],\n",
       " ['Call'],\n",
       " ['Name:super'],\n",
       " ['Name:TestArithmeticOps'],\n",
       " ['Name:self'],\n",
       " ['Name:s'],\n",
       " ['Name:op_name'],\n",
       " ['Name:other'],\n",
       " ['exc'],\n",
       " ['NameConstant'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:data'],\n",
       " ['arg:all_arithmetic_operators'],\n",
       " ['Name:op_name'],\n",
       " ['Name:all_arithmetic_operators'],\n",
       " ['Name:s'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['Name:data'],\n",
       " ['Name:context'],\n",
       " ['Call'],\n",
       " ['getcontext'],\n",
       " ['Name:decimal'],\n",
       " ['Name:divbyzerotrap'],\n",
       " ['Subscript'],\n",
       " ['traps'],\n",
       " ['Name:context'],\n",
       " ['Index'],\n",
       " ['DivisionByZero'],\n",
       " ['Name:decimal'],\n",
       " ['Name:invalidoptrap'],\n",
       " ['Subscript'],\n",
       " ['traps'],\n",
       " ['Name:context'],\n",
       " ['Index'],\n",
       " ['InvalidOperation'],\n",
       " ['Name:decimal'],\n",
       " ['Subscript'],\n",
       " ['traps'],\n",
       " ['Name:context'],\n",
       " ['Index'],\n",
       " ['DivisionByZero'],\n",
       " ['Name:decimal'],\n",
       " ['Num'],\n",
       " ['Subscript'],\n",
       " ['traps'],\n",
       " ['Name:context'],\n",
       " ['Index'],\n",
       " ['InvalidOperation'],\n",
       " ['Name:decimal'],\n",
       " ['Num'],\n",
       " ['Name:other'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['ListComp'],\n",
       " ['Call'],\n",
       " ['Name:int'],\n",
       " ['BinOp: Mult()'],\n",
       " ['Name:d'],\n",
       " ['Mult'],\n",
       " ['Num'],\n",
       " ['comprehension'],\n",
       " ['Name:d'],\n",
       " ['Name:data'],\n",
       " ['Call'],\n",
       " ['check_opname'],\n",
       " ['Name:self'],\n",
       " ['Name:s'],\n",
       " ['Name:op_name'],\n",
       " ['Name:other'],\n",
       " ['If'],\n",
       " ['Compare'],\n",
       " ['Str'],\n",
       " ['NotIn'],\n",
       " ['Name:op_name'],\n",
       " ['Call'],\n",
       " ['check_opname'],\n",
       " ['Name:self'],\n",
       " ['Name:s'],\n",
       " ['Name:op_name'],\n",
       " ['BinOp: Mult()'],\n",
       " ['Name:s'],\n",
       " ['Mult'],\n",
       " ['Num'],\n",
       " ['Call'],\n",
       " ['check_opname'],\n",
       " ['Name:self'],\n",
       " ['Name:s'],\n",
       " ['Name:op_name'],\n",
       " ['Num'],\n",
       " ['Call'],\n",
       " ['check_opname'],\n",
       " ['Name:self'],\n",
       " ['Name:s'],\n",
       " ['Name:op_name'],\n",
       " ['Num'],\n",
       " ['Subscript'],\n",
       " ['traps'],\n",
       " ['Name:context'],\n",
       " ['Index'],\n",
       " ['DivisionByZero'],\n",
       " ['Name:decimal'],\n",
       " ['Name:divbyzerotrap'],\n",
       " ['Subscript'],\n",
       " ['traps'],\n",
       " ['Name:context'],\n",
       " ['Index'],\n",
       " ['InvalidOperation'],\n",
       " ['Name:decimal'],\n",
       " ['Name:invalidoptrap'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:data'],\n",
       " ['Pass'],\n",
       " ['Call'],\n",
       " ['skip'],\n",
       " ['mark'],\n",
       " ['Name:pytest'],\n",
       " ['reason'],\n",
       " ['Str'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['Pass'],\n",
       " ['ClassDef'],\n",
       " ['Name:BaseDecimal'],\n",
       " ['BaseComparisonOpsTests'],\n",
       " ['Name:base'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:s'],\n",
       " ['arg:op_name'],\n",
       " ['arg:other'],\n",
       " ['arg:exc'],\n",
       " ['NameConstant'],\n",
       " ['Call'],\n",
       " ['check_opname'],\n",
       " ['Call'],\n",
       " ['Name:super'],\n",
       " ['Name:TestComparisonOps'],\n",
       " ['Name:self'],\n",
       " ['Name:s'],\n",
       " ['Name:op_name'],\n",
       " ['Name:other'],\n",
       " ['exc'],\n",
       " ['NameConstant'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:s'],\n",
       " ['arg:data'],\n",
       " ['arg:op_name'],\n",
       " ['arg:other'],\n",
       " ['Call'],\n",
       " ['check_opname'],\n",
       " ['Name:self'],\n",
       " ['Name:s'],\n",
       " ['Name:op_name'],\n",
       " ['Name:other'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:data'],\n",
       " ['arg:all_compare_operators'],\n",
       " ['Name:op_name'],\n",
       " ['Name:all_compare_operators'],\n",
       " ['Name:s'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['Name:data'],\n",
       " ['Call'],\n",
       " ['_compare_other'],\n",
       " ['Name:self'],\n",
       " ['Name:s'],\n",
       " ['Name:data'],\n",
       " ['Name:op_name'],\n",
       " ['Num'],\n",
       " ['FunctionDef'],\n",
       " ['arguments'],\n",
       " ['arg:self'],\n",
       " ['arg:data'],\n",
       " ['arg:all_compare_operators'],\n",
       " ['Name:op_name'],\n",
       " ['Name:all_compare_operators'],\n",
       " ['Name:s'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['Name:data'],\n",
       " ['Name:alter'],\n",
       " ['Call'],\n",
       " ['choice'],\n",
       " ['random'],\n",
       " ['Name:np'],\n",
       " ['List'],\n",
       " ['UnaryOp'],\n",
       " ['USub'],\n",
       " ['Num'],\n",
       " ['Num'],\n",
       " ['Num'],\n",
       " ['Call'],\n",
       " ['Name:len'],\n",
       " ['Name:data'],\n",
       " ['Name:other'],\n",
       " ['BinOp: Mult()'],\n",
       " ['Call'],\n",
       " ['Series'],\n",
       " ['Name:pd'],\n",
       " ['Name:data'],\n",
       " ['Mult'],\n",
       " ['ListComp'],\n",
       " ['Call'],\n",
       " ['Decimal'],\n",
       " ['Name:decimal'],\n",
       " ['Call'],\n",
       " ['Name:pow'],\n",
       " ['Num'],\n",
       " ['Name:i'],\n",
       " ['comprehension'],\n",
       " ['Name:i'],\n",
       " ['Name:alter'],\n",
       " ['Call'],\n",
       " ['_compare_other'],\n",
       " ['Name:self'],\n",
       " ['Name:s'],\n",
       " ['Name:data'],\n",
       " ['Name:op_name'],\n",
       " ['Name:other']]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Call</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Str</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name:decimal</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arguments</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FunctionDef</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arg:all_data</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name:random</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name:pow</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImportFrom:tm</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>format</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               token\n",
       "Call             119\n",
       "Str               45\n",
       "Name:decimal      32\n",
       "arguments         29\n",
       "FunctionDef       28\n",
       "...              ...\n",
       "arg:all_data       1\n",
       "Name:random        1\n",
       "Name:pow           1\n",
       "ImportFrom:tm      1\n",
       "format             1\n",
       "\n",
       "[186 rows x 1 columns]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we count the number of tokens for 'before-commit' file\n",
    "dtobj_bfore = pd.DataFrame(file_contents, columns=['token'])\n",
    "\n",
    "tokens_before =pd.DataFrame(dtobj_bfore['token'].value_counts())\n",
    "tokens_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below we are doing the same strategy but this time for 'commit-after' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tokenize.open(\"after-commit.py\") as sf:  # need the tokenize.open for source files and not a string\n",
    "    source_file_after = sf.read()\n",
    "\n",
    "after = ast.parse(source_file_after)\n",
    "ast_after = ast.parse(source_file_after)\n",
    "aft_obj = FuncParser()\n",
    "aft_tree = ast.parse(ast_after)\n",
    "file_contents = []\n",
    "aft_obj.visit(aft_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Call</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Str</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name:decimal</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arguments</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FunctionDef</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Import:pytest</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name:_</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assert_extension_array_equal</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>format</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              token\n",
       "Call                            116\n",
       "Str                              45\n",
       "Name:decimal                     32\n",
       "arguments                        27\n",
       "FunctionDef                      26\n",
       "...                             ...\n",
       "Import:pytest                     1\n",
       "Name:_                            1\n",
       "context                           1\n",
       "assert_extension_array_equal      1\n",
       "format                            1\n",
       "\n",
       "[182 rows x 1 columns]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtobj_after = pd.DataFrame(file_contents, columns=['token'])\n",
    "\n",
    "tokens_after =pd.DataFrame(dtobj_after['token'].value_counts())\n",
    "tokens_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we calculate the difference of tokens into both file, before and after. those tokens which has '0' counts are new tokens wich are exist in only one of the files (before or after)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = tokens_after.subtract(tokens_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Call</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FunctionDef</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name:DecimalArray</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Name:_</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Name:count</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Name:gen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Name:make_data</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Name:pytest</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Name:range</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Yield</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arg:count</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>arguments</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fixture</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  token\n",
       "0                Call    3.0\n",
       "1                 For    1.0\n",
       "2         FunctionDef    2.0\n",
       "3   Name:DecimalArray    1.0\n",
       "4              Name:_    1.0\n",
       "5          Name:count    0.0\n",
       "6            Name:gen    0.0\n",
       "7      Name:make_data    1.0\n",
       "8         Name:pytest    1.0\n",
       "9          Name:range    1.0\n",
       "10              Yield    0.0\n",
       "11          arg:count    0.0\n",
       "12          arguments    2.0\n",
       "13            fixture    1.0"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_token = diff[(diff.select_dtypes(include=['number']) != 0).any(1)]\n",
    "diff_token=diff_token.fillna(0)\n",
    "diff_token= diff_token.abs()\n",
    "diff_token = diff_token.reset_index()\n",
    "diff_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a list to save the result per commit and its developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_author_token = pd.DataFrame(columns=['Author','msg', 'tokens', 'counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_author_token = df_author_token.append({'Author':tf_source['Author'][1],'msg':tf_source['msg'][1]\n",
    "                                         ,'tokens':diff_token['index'],'counts':diff_token['token']},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>msg</th>\n",
       "      <th>tokens</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>Provide default implementation for `data_repat...</td>\n",
       "      <td>0                  Call\n",
       "1                   Fo...</td>\n",
       "      <td>0     3.0\n",
       "1     1.0\n",
       "2     2.0\n",
       "3     1.0\n",
       "4     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Author                                                msg  \\\n",
       "0  Tom Augspurger  Provide default implementation for `data_repat...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  0                  Call\n",
       "1                   Fo...   \n",
       "\n",
       "                                              counts  \n",
       "0  0     3.0\n",
       "1     1.0\n",
       "2     2.0\n",
       "3     1.0\n",
       "4     ...  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_author_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned above, here I am showing the step by step of a function that will be apply to all dataset in continue.\n",
    "below I am creating the dictiory of extracted tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_author_token['tokens'][0]\n",
    "y=df_author_token['counts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Call': 1, 'For': 2, 'FunctionDef': 3, 'Name:DecimalArray': 4, 'Name:_': 5, 'Name:count': 6, 'Name:gen': 7, 'Name:make_data': 8, 'Name:pytest': 9, 'Name:range': 10, 'Yield': 11, 'arg:count': 12, 'arguments': 13, 'fixture': 14}\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "i = 1\n",
    "for word in x:\n",
    "    if word in vocab:\n",
    "        continue\n",
    "    else:\n",
    "        vocab[word]=i\n",
    "        i+=1\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tom Augspurger', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = [df_author_token['Author'][0]]+[0]*len(vocab)\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tom Augspurger',\n",
       " 3.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I try to count the number of each vocab in diff_token of each commit per developer\n",
    "i=0\n",
    "for word in x:\n",
    "    one[vocab[word]]+=y[i]\n",
    "    i+=1\n",
    "    \n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new list to repeat all above steps in a loop function\n",
    "df_author_token = pd.DataFrame(columns=['Author','msg', 'tokens', 'counts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Run the AST function on whole dataset to extract tokens\n",
    "  - ** please be inform that two code sections below loops within all code-commit and bug-commit to count the difference of tokens and it takes around 30 minutes to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "error=0\n",
    "vocab = {}\n",
    "j = 1\n",
    "for row in tf_source.iterrows():\n",
    "    if tf_source['Commit_before'][i] is not None:\n",
    "        text_before=tf_source['Commit_before'][i]\n",
    "    if tf_source['Commit_after'][i] is not None:\n",
    "        text_after=tf_source['Commit_after'][i]\n",
    "    before = open(\"before-commit.py\", \"w+\")\n",
    "    after = open(\"after-commit.py\", \"w+\")\n",
    "    try:\n",
    "        before.write(text_before)\n",
    "    except ValueError:\n",
    "        #print(\"Oops!  Error in writing to the before file #\",i)\n",
    "        error+=1\n",
    "    try:\n",
    "        after.write(text_after)\n",
    "    except ValueError:\n",
    "        #print(\"Oops!  Error in writing to the After file #\",i)\n",
    "        error+=1\n",
    "    #this for commit before\n",
    "    with tokenize.open(\"before-commit.py\") as sf:  # need the tokenize.open for source files and not a string\n",
    "        try:\n",
    "            source_file_before = sf.read()\n",
    "            ast_before = ast.parse(source_file_before)\n",
    "        except ValueError:\n",
    "            error+=1\n",
    "            #print(\"Oops!  Error in before commit #\",i)       \n",
    "    bf_obj = FuncParser()\n",
    "    bf_tree = ast.parse(ast_before)\n",
    "    file_contents = []\n",
    "    bf_obj.visit(bf_tree)\n",
    "    #counting tokens in file before\n",
    "    dtobj_bfore = pd.DataFrame(file_contents, columns=['token'])\n",
    "    tokens_before =pd.DataFrame(dtobj_bfore['token'].value_counts())\n",
    "    #doing the same for file after\n",
    "    with tokenize.open(\"after-commit.py\") as sf:  # need the tokenize.open for source files and not a string\n",
    "        try:\n",
    "            source_file_after = sf.read()\n",
    "            ast_after = ast.parse(source_file_after)\n",
    "        except ValueError:\n",
    "            error+=1\n",
    "            #print(\"Oops!  Error in after commit #\",i)\n",
    "    aft_obj = FuncParser()\n",
    "    aft_tree = ast.parse(ast_after)\n",
    "    file_contents = []\n",
    "    aft_obj.visit(aft_tree)\n",
    "    #counting\n",
    "    dtobj_after = pd.DataFrame(file_contents, columns=['token'])\n",
    "    tokens_after =pd.DataFrame(dtobj_after['token'].value_counts())\n",
    "    #calculating the difference\n",
    "    diff = tokens_after.subtract(tokens_before)\n",
    "    diff_token = diff[(diff.select_dtypes(include=['number']) != 0).any(1)]\n",
    "    diff_token=diff_token.fillna(0)\n",
    "    diff_token= diff_token.abs()\n",
    "    diff_token = diff_token.reset_index()\n",
    "    df_author_token = df_author_token.append({'Author':tf_source['Author'][i],'msg':tf_source['msg'][i]\n",
    "                                         ,'tokens':diff_token['index'],'counts':diff_token['token']},ignore_index=True)\n",
    "    i+=1\n",
    "    for word in diff_token['index']:\n",
    "        if word in vocab:\n",
    "            continue\n",
    "        else:\n",
    "            vocab[word]=j\n",
    "            j+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "bug_error=0\n",
    "for row in tf_bug.iterrows():\n",
    "    if tf_bug['Commit_before'][i] is not None:\n",
    "        text_before=tf_bug['Commit_before'][i]\n",
    "    if tf_bug['Commit_after'][i] is not None:\n",
    "        text_after=tf_bug['Commit_after'][i]\n",
    "    before = open(\"before-commit.py\", \"w+\")\n",
    "    after = open(\"after-commit.py\", \"w+\")\n",
    "    try:\n",
    "        before.write(text_before)\n",
    "    except ValueError:\n",
    "        #print(\"Oops!  Error in writing to the before file #\",i)\n",
    "        bug_error+=1\n",
    "    try:\n",
    "        after.write(text_after)\n",
    "    except ValueError:\n",
    "        #print(\"Oops!  Error in writing to the After file #\",i)\n",
    "        bug_error+=1\n",
    "    #this for commit before\n",
    "    with tokenize.open(\"before-commit.py\") as sf:  # need the tokenize.open for source files and not a string\n",
    "        try:\n",
    "            source_file_before = sf.read()\n",
    "            ast_before = ast.parse(source_file_before)\n",
    "        except ValueError:\n",
    "            bug_error+=1\n",
    "            #print(\"Oops!  Error in before commit #\",i)       \n",
    "    bf_obj = FuncParser()\n",
    "    bf_tree = ast.parse(ast_before)\n",
    "    file_contents = []\n",
    "    bf_obj.visit(bf_tree)\n",
    "    #counting tokens in file before\n",
    "    dtobj_bfore = pd.DataFrame(file_contents, columns=['token'])\n",
    "    tokens_before =pd.DataFrame(dtobj_bfore['token'].value_counts())\n",
    "    #doing the same for file after\n",
    "    with tokenize.open(\"after-commit.py\") as sf:  # need the tokenize.open for source files and not a string\n",
    "        try:\n",
    "            source_file_after = sf.read()\n",
    "            ast_after = ast.parse(source_file_after)\n",
    "        except ValueError:\n",
    "            bug_error+=1\n",
    "            #print(\"Oops!  Error in after commit #\",i)\n",
    "    aft_obj = FuncParser()\n",
    "    aft_tree = ast.parse(ast_after)\n",
    "    file_contents = []\n",
    "    aft_obj.visit(aft_tree)\n",
    "    #counting\n",
    "    dtobj_after = pd.DataFrame(file_contents, columns=['token'])\n",
    "    tokens_after =pd.DataFrame(dtobj_after['token'].value_counts())\n",
    "    #calculating the difference\n",
    "    diff = tokens_after.subtract(tokens_before)\n",
    "    diff_token = diff[(diff.select_dtypes(include=['number']) != 0).any(1)]\n",
    "    diff_token=diff_token.fillna(0)\n",
    "    diff_token= diff_token.abs()\n",
    "    diff_token = diff_token.reset_index()\n",
    "    df_author_token = df_author_token.append({'Author':tf_bug['Author'][i],'msg':tf_bug['msg'][i]\n",
    "                                         ,'tokens':diff_token['index'],'counts':diff_token['token']},ignore_index=True)\n",
    "    i+=1\n",
    "    for word in diff_token['index']:\n",
    "        if word in vocab:\n",
    "            continue\n",
    "        else:\n",
    "            vocab[word]=j\n",
    "            j+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9100, 4)"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_author_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17621"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of vocab\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Call': 1,\n",
       " 'For': 2,\n",
       " 'FunctionDef': 3,\n",
       " 'Name:DecimalArray': 4,\n",
       " 'Name:_': 5,\n",
       " 'Name:count': 6,\n",
       " 'Name:gen': 7,\n",
       " 'Name:make_data': 8,\n",
       " 'Name:pytest': 9,\n",
       " 'Name:range': 10,\n",
       " 'Yield': 11,\n",
       " 'arg:count': 12,\n",
       " 'arguments': 13,\n",
       " 'fixture': 14,\n",
       " 'Name:Categorical': 15,\n",
       " 'Str': 16,\n",
       " 'Name:data': 17,\n",
       " 'arg:data': 18,\n",
       " 'Compare': 19,\n",
       " 'If': 20,\n",
       " 'IsNot': 21,\n",
       " 'Name:dtype': 22,\n",
       " 'Name:keep_tz': 23,\n",
       " 'Name:self': 24,\n",
       " 'NameConstant': 25,\n",
       " 'Return': 26,\n",
       " '_to_embed': 27,\n",
       " 'arg:dtype': 28,\n",
       " 'arg:keep_tz': 29,\n",
       " 'arg:self': 30,\n",
       " 'astype': 31,\n",
       " 'keep_tz': 32,\n",
       " 'Name:values': 33,\n",
       " 'Name:object': 34,\n",
       " 'values': 35,\n",
       " 'BinOp: Mod()': 36,\n",
       " 'Index': 37,\n",
       " 'Mod': 38,\n",
       " 'Name:NDFrame': 39,\n",
       " 'Name:Substitution': 40,\n",
       " 'Name:_shared_docs': 41,\n",
       " 'Subscript': 42,\n",
       " '__doc__': 43,\n",
       " 'reindex': 44,\n",
       " 'sort_index': 45,\n",
       " 'sort_values': 46,\n",
       " 'Name:Appender': 47,\n",
       " 'Name:_shared_doc_kwargs': 48,\n",
       " 'Name:dict': 49,\n",
       " 'Name:rename': 50,\n",
       " 'axes': 51,\n",
       " 'klass': 52,\n",
       " 'optional_axis': 53,\n",
       " 'optional_labels': 54,\n",
       " 'optional_mapper': 55,\n",
       " 'Name:Panel': 56,\n",
       " 'Name:args': 57,\n",
       " 'Name:kwargs': 58,\n",
       " 'Name:super': 59,\n",
       " 'Starred': 60,\n",
       " 'arg:args': 61,\n",
       " 'arg:kwargs': 62,\n",
       " 'rename': 63,\n",
       " 'transpose': 64,\n",
       " 'NDFrame': 65,\n",
       " '_shared_docs': 66,\n",
       " '_take': 67,\n",
       " 'Import:Substitution': 68,\n",
       " 'take': 69,\n",
       " 'Name:closed': 70,\n",
       " 'Name:cls': 71,\n",
       " 'Name:copy': 72,\n",
       " 'Name:fastpath': 73,\n",
       " '_simple_new': 74,\n",
       " 'arg:fastpath': 75,\n",
       " 'copy': 76,\n",
       " 'dtype': 77,\n",
       " 'left': 78,\n",
       " 'right': 79,\n",
       " 'verify_integrity': 80,\n",
       " 'And': 81,\n",
       " 'BoolOp: And()': 82,\n",
       " 'Name:Index': 83,\n",
       " 'Name:Interval': 84,\n",
       " 'Name:IntervalArray': 85,\n",
       " 'Name:cache_readonly': 86,\n",
       " 'Name:i': 87,\n",
       " 'Name:is_scalar': 88,\n",
       " 'Name:left': 89,\n",
       " 'Name:len': 90,\n",
       " 'Name:mask': 91,\n",
       " 'Name:name': 92,\n",
       " 'Name:np': 93,\n",
       " 'Name:property': 94,\n",
       " 'Name:right': 95,\n",
       " 'Name:type': 96,\n",
       " 'Name:value': 97,\n",
       " 'Not': 98,\n",
       " 'UnaryOp': 99,\n",
       " '_data': 100,\n",
       " '_isnan': 101,\n",
       " '_na_value': 102,\n",
       " 'any': 103,\n",
       " 'array': 104,\n",
       " 'closed': 105,\n",
       " 'empty': 106,\n",
       " 'fastpath': 107,\n",
       " 'nan': 108,\n",
       " '_shallow_copy': 109,\n",
       " 'name': 110,\n",
       " 'Import:ABCPeriodIndex': 111,\n",
       " 'Import:is_period_dtype': 112,\n",
       " 'Name:ABCPeriodIndex': 113,\n",
       " 'Name:is_period_dtype': 114,\n",
       " 'Name:isinstance': 115,\n",
       " 'Name:l': 116,\n",
       " 'Name:length': 117,\n",
       " 'Is': 118,\n",
       " 'arg:mask': 119,\n",
       " 'mask': 120,\n",
       " 'Assert': 121,\n",
       " 'Eq': 122,\n",
       " 'List': 123,\n",
       " 'Name:median_expected': 124,\n",
       " 'Name:median_result': 125,\n",
       " 'Name:nanops': 126,\n",
       " 'Name:operation': 127,\n",
       " 'Name:pd': 128,\n",
       " 'Name:s': 129,\n",
       " 'Num': 130,\n",
       " 'Series': 131,\n",
       " 'arg:operation': 132,\n",
       " 'isna': 133,\n",
       " 'mark': 134,\n",
       " 'nanall': 135,\n",
       " 'nanany': 136,\n",
       " 'nanargmax': 137,\n",
       " 'nanargmin': 138,\n",
       " 'nankurt': 139,\n",
       " 'nanmax': 140,\n",
       " 'nanmean': 141,\n",
       " 'nanmedian': 142,\n",
       " 'nanmin': 143,\n",
       " 'nanprod': 144,\n",
       " 'nansem': 145,\n",
       " 'nanskew': 146,\n",
       " 'nanstd': 147,\n",
       " 'nansum': 148,\n",
       " 'nanvar': 149,\n",
       " 'parametrize': 150,\n",
       " 'Name:Series': 151,\n",
       " 'Name:new_data': 152,\n",
       " 'Name:ops': 153,\n",
       " 'Name:other': 154,\n",
       " 'Name:try_cast': 155,\n",
       " '_constructor': 156,\n",
       " 'axis': 157,\n",
       " 'columns': 158,\n",
       " 'dispatch_to_series': 159,\n",
       " 'eval': 160,\n",
       " 'func': 161,\n",
       " 'index': 162,\n",
       " 'other': 163,\n",
       " 'try_cast': 164,\n",
       " 'DictComp': 165,\n",
       " 'ExtSlice': 166,\n",
       " 'IfExp': 167,\n",
       " 'In': 168,\n",
       " 'Name:ABCSeries': 169,\n",
       " 'Name:a': 170,\n",
       " 'Name:axis': 171,\n",
       " 'Name:b': 172,\n",
       " 'Name:func': 173,\n",
       " 'Name:op': 174,\n",
       " 'Name:pass_op': 175,\n",
       " 'Slice': 176,\n",
       " 'arg:a': 177,\n",
       " 'arg:axis': 178,\n",
       " 'arg:b': 179,\n",
       " 'comprehension': 180,\n",
       " 'equals': 181,\n",
       " 'iloc': 182,\n",
       " 'DataFrame': 183,\n",
       " 'Name:box': 184,\n",
       " 'Name:box_df_broadcast_failure': 185,\n",
       " 'Name:box_df_fail': 186,\n",
       " 'Name:obox': 187,\n",
       " 'Name:vec': 188,\n",
       " 'Raise': 189,\n",
       " 'arg:box': 190,\n",
       " 'arg:box_df_broadcast_failure': 191,\n",
       " 'arg:box_df_fail': 192,\n",
       " 'reason': 193,\n",
       " 'xfail': 194,\n",
       " 'Lambda': 195,\n",
       " 'Name:TypeError': 196,\n",
       " 'Name:ValueError': 197,\n",
       " 'Name:tester': 198,\n",
       " 'With': 199,\n",
       " 'withitem': 200,\n",
       " 'Name:Exception': 201,\n",
       " 'Name:res': 202,\n",
       " 'Pass': 203,\n",
       " 'asarray': 204,\n",
       " 'Import:to_decimal': 205,\n",
       " 'Import:make_data': 206,\n",
       " 'Import:DecimalDtype': 207,\n",
       " 'Name:__all__': 208,\n",
       " 'ImportFrom:array': 209,\n",
       " 'Import:DecimalArray': 210,\n",
       " 'Add': 211,\n",
       " 'BinOp: Add()': 212,\n",
       " 'ClassDef': 213,\n",
       " 'Decimal': 214,\n",
       " 'Import:operator': 215,\n",
       " 'Import:random': 216,\n",
       " 'ListComp': 217,\n",
       " 'Name:DecimalArrayWithoutCoercion': 218,\n",
       " 'Name:DecimalArrayWithoutFromSequence': 219,\n",
       " 'Name:KeyError': 220,\n",
       " 'Name:arr': 221,\n",
       " 'Name:class_': 222,\n",
       " 'Name:classmethod': 223,\n",
       " 'Name:decimal': 224,\n",
       " 'Name:expected': 225,\n",
       " 'Name:operator': 226,\n",
       " 'Name:random': 227,\n",
       " 'Name:result': 228,\n",
       " 'Name:ser': 229,\n",
       " 'Name:tm': 230,\n",
       " '_add_arithmetic_ops': 231,\n",
       " '_create_method': 232,\n",
       " 'add': 233,\n",
       " 'arg:class_': 234,\n",
       " 'arg:cls': 235,\n",
       " 'arg:copy': 236,\n",
       " 'arg:op': 237,\n",
       " 'arg:scalars': 238,\n",
       " 'assert_numpy_array_equal': 239,\n",
       " 'assert_series_equal': 240,\n",
       " 'coerce_to_dtype': 241,\n",
       " 'combine': 242,\n",
       " 'random': 243,\n",
       " 'Import:JSONArray': 244,\n",
       " 'Import:JSONDtype': 245,\n",
       " 'Import:string': 246,\n",
       " 'Name:collections': 247,\n",
       " 'Name:string': 248,\n",
       " 'Tuple': 249,\n",
       " 'UserDict': 250,\n",
       " 'ascii_letters': 251,\n",
       " 'choice': 252,\n",
       " 'randint': 253,\n",
       " 'all': 254,\n",
       " 'errstate': 255,\n",
       " 'BoolOp: Or()': 256,\n",
       " 'Name:is_float_dtype': 257,\n",
       " 'Or': 258,\n",
       " 'Dict': 259,\n",
       " 'Name:check': 260,\n",
       " 'Name:is_bool_dtype': 261,\n",
       " 'Name:is_categorical_dtype': 262,\n",
       " 'Name:is_datetime64_any_dtype': 263,\n",
       " 'Name:is_datetime64_dtype': 264,\n",
       " 'Name:is_datetime64_ns_dtype': 265,\n",
       " 'Name:is_datetime64tz_dtype': 266,\n",
       " 'Name:is_interval_dtype': 267,\n",
       " 'Name:is_string_dtype': 268,\n",
       " 'arg:check': 269,\n",
       " 'assert_produces_warning': 270,\n",
       " 'Name:all_arithmetic_operators': 271,\n",
       " 'Name:df': 272,\n",
       " 'Name:getattr': 273,\n",
       " 'arg:all_arithmetic_operators': 274,\n",
       " 'Import:DatetimeTZDtypeType': 275,\n",
       " 'Import:Interval': 276,\n",
       " 'Import:IntervalDtypeType': 277,\n",
       " 'Import:Period': 278,\n",
       " 'Import:PeriodDtypeType': 279,\n",
       " 'Import:Timestamp': 280,\n",
       " 'ImportFrom:pandas._libs.interval': 281,\n",
       " 'Name:DatetimeTZDtypeType': 282,\n",
       " 'Name:IntervalDtypeType': 283,\n",
       " 'Name:Period': 284,\n",
       " 'Name:PeriodDtypeType': 285,\n",
       " 'Name:Timestamp': 286,\n",
       " 'Import:NaT': 287,\n",
       " 'ImportFrom:pandas': 288,\n",
       " 'ImportFrom:pandas._libs.tslibs': 289,\n",
       " 'Name:NaT': 290,\n",
       " 'Name:compat': 291,\n",
       " 'text_type': 292,\n",
       " 'DatetimeTZDtypeType': 293,\n",
       " 'Interval': 294,\n",
       " 'IntervalDtypeType': 295,\n",
       " 'Name:com': 296,\n",
       " 'Period': 297,\n",
       " 'PeriodDtypeType': 298,\n",
       " 'Timestamp': 299,\n",
       " 'Name:assert_equal': 300,\n",
       " 'Name:assert_method': 301,\n",
       " 'arg:assert_equal': 302,\n",
       " 'arg:assert_method': 303,\n",
       " 'assert_equal': 304,\n",
       " 'Name:assert_func': 305,\n",
       " 'arg:assert_func': 306,\n",
       " 'assert_index_equal': 307,\n",
       " 'Name:ExtensionArray': 308,\n",
       " 'Name:assert_extension_array_equal': 309,\n",
       " 'Name:assert_numpy_array_equal': 310,\n",
       " 'ndarray': 311,\n",
       " 'Name:freq': 312,\n",
       " 'Name:periods': 313,\n",
       " '_time_shift': 314,\n",
       " 'arg:freq': 315,\n",
       " 'arg:periods': 316,\n",
       " 'freq': 317,\n",
       " 'periods': 318,\n",
       " 'shift': 319,\n",
       " 'Name:n': 320,\n",
       " 'arg:n': 321,\n",
       " 'BinOp: Sub()': 322,\n",
       " 'Gt': 323,\n",
       " 'Import:TestData': 324,\n",
       " 'ImportFrom:pandas.tests.frame.common': 325,\n",
       " 'Name:DataFrame': 326,\n",
       " 'Name:TestData': 327,\n",
       " 'Name:_check_bool_op': 328,\n",
       " 'Name:_check_stat_op': 329,\n",
       " 'Name:alternative': 330,\n",
       " 'Name:bool_frame_with_na': 331,\n",
       " 'Name:check_minp': 332,\n",
       " 'Name:datetime_frame': 333,\n",
       " 'Name:empty_frame': 334,\n",
       " 'Name:exp': 335,\n",
       " 'Name:float_frame': 336,\n",
       " 'Name:float_frame_with_na': 337,\n",
       " 'Name:float_string_frame': 338,\n",
       " 'Name:frame': 339,\n",
       " 'Name:int_frame': 340,\n",
       " 'Name:main_frame': 341,\n",
       " 'Name:mixed_float_frame': 342,\n",
       " 'Name:nan': 343,\n",
       " 'Name:simple_frame': 344,\n",
       " 'Name:wrapper': 345,\n",
       " 'Sub': 346,\n",
       " 'USub': 347,\n",
       " '_check_bool_op': 348,\n",
       " '_check_stat_op': 349,\n",
       " 'arg:bool_frame_with_na': 350,\n",
       " 'arg:check_minp': 351,\n",
       " 'arg:datetime_frame': 352,\n",
       " 'arg:empty_frame': 353,\n",
       " 'arg:float_frame': 354,\n",
       " 'arg:float_frame_with_na': 355,\n",
       " 'arg:float_string_frame': 356,\n",
       " 'arg:int_frame': 357,\n",
       " 'arg:main_frame': 358,\n",
       " 'arg:mixed_float_frame': 359,\n",
       " 'arg:simple_frame': 360,\n",
       " 'assert_frame_equal': 361,\n",
       " 'corr': 362,\n",
       " 'frame': 363,\n",
       " 'intframe': 364,\n",
       " 'loc': 365,\n",
       " 'min_periods': 366,\n",
       " 'mixed_float': 367,\n",
       " 'mixed_frame': 368,\n",
       " 'simple': 369,\n",
       " 'tsframe': 370,\n",
       " 'Name:x': 371,\n",
       " '__name__': 372,\n",
       " 'arg:x': 373,\n",
       " 'ids': 374,\n",
       " 'marks': 375,\n",
       " 'param': 376,\n",
       " 'raises': 377,\n",
       " 'strict': 378,\n",
       " 'Name:_seriesd': 379,\n",
       " 'Name:df1a_bool': 380,\n",
       " 'Name:df1a_int': 381,\n",
       " 'Name:df2': 382,\n",
       " 'Name:dfa': 383,\n",
       " 'getSeriesData': 384,\n",
       " 'makeStringSeries': 385,\n",
       " 'series': 386,\n",
       " 'Name:_f': 387,\n",
       " 'Name:assert_bool_op_api': 388,\n",
       " 'Name:assert_bool_op_calc': 389,\n",
       " 'Name:assert_stat_op_api': 390,\n",
       " 'Name:assert_stat_op_calc': 391,\n",
       " 'Name:int': 392,\n",
       " 'Name:opname': 393,\n",
       " 'arg:frame': 394,\n",
       " 'arg:name': 395,\n",
       " 'arg:opname': 396,\n",
       " 'assert_raises_regex': 397,\n",
       " 'has_bool_only': 398,\n",
       " 'has_numeric_only': 399,\n",
       " 'has_skipna': 400,\n",
       " 'ExceptHandler': 401,\n",
       " 'Name:AttributeError': 402,\n",
       " 'Name:to_series': 403,\n",
       " 'NotEq': 404,\n",
       " 'Try': 405,\n",
       " 'broadcast_to': 406,\n",
       " 'shape': 407,\n",
       " 'tile': 408,\n",
       " 'Name:collike': 409,\n",
       " 'Name:exvals': 410,\n",
       " 'Name:rowlike': 411,\n",
       " 'arange': 412,\n",
       " 'common_type': 413,\n",
       " 'reshape': 414,\n",
       " 'squeeze': 415,\n",
       " 'Name:rs': 416,\n",
       " 'Name:xp': 417,\n",
       " 'Import:PeriodArrayMixin': 418,\n",
       " 'Import:get_period_alias': 419,\n",
       " 'ImportFrom:pandas.core.arrays.period': 420,\n",
       " 'Name:PeriodArrayMixin': 421,\n",
       " 'Name:UserWarning': 422,\n",
       " 'Name:get_period_alias': 423,\n",
       " 'Name:hasattr': 424,\n",
       " 'Name:warnings': 425,\n",
       " 'freqstr': 426,\n",
       " 'inferred_freq': 427,\n",
       " 'tz': 428,\n",
       " 'warn': 429,\n",
       " 'Import:DatetimeArrayMixin': 430,\n",
       " 'Import:Timedelta': 431,\n",
       " 'Import:is_datetime64_dtype': 432,\n",
       " 'ImportFrom:pandas.core.arrays.datetimes': 433,\n",
       " 'Name:DatetimeArrayMixin': 434,\n",
       " 'Name:Timedelta': 435,\n",
       " 'Name:adjust': 436,\n",
       " 'Name:base': 437,\n",
       " 'Name:dt64arr_to_periodarr': 438,\n",
       " 'Name:end': 439,\n",
       " 'Name:frequencies': 440,\n",
       " 'Name:how': 441,\n",
       " 'Name:libperiod': 442,\n",
       " 'Name:mult': 443,\n",
       " 'Name:tz': 444,\n",
       " '_maybe_convert_freq': 445,\n",
       " '_ndarray_values': 446,\n",
       " '_validate_end_alias': 447,\n",
       " 'arg:how': 448,\n",
       " 'arg:tz': 449,\n",
       " 'asfreq': 450,\n",
       " 'dt64arr_to_periodarr': 451,\n",
       " 'get_freq_code': 452,\n",
       " 'get_to_timestamp_base': 453,\n",
       " 'how': 454,\n",
       " 'periodarr_to_dt64arr': 455,\n",
       " 'to_timestamp': 456,\n",
       " 'view': 457,\n",
       " 'Name:DatetimeIndex': 458,\n",
       " 'Name:msg': 459,\n",
       " 'to_period': 460,\n",
       " 'Import:_validate_end_alias': 461,\n",
       " 'Import:datetimelike': 462,\n",
       " 'Import:dt64arr_to_periodarr': 463,\n",
       " 'Import:pandas.tseries.frequencies': 464,\n",
       " 'ImportFrom:dtl': 465,\n",
       " 'ImportFrom:frequencies': 466,\n",
       " 'ImportFrom:pandas.core.arrays': 467,\n",
       " 'Name:_gfc': 468,\n",
       " 'Name:_validate_end_alias': 469,\n",
       " 'Name:dtl': 470,\n",
       " 'Name:is_float': 471,\n",
       " 'Name:is_integer': 472,\n",
       " 'Name:period': 473,\n",
       " 'end_time': 474,\n",
       " 'fget': 475,\n",
       " 'format': 476,\n",
       " 'start_time': 477,\n",
       " 'validate_periods': 478,\n",
       " 'Name:TimedeltaIndex': 479,\n",
       " 'DatetimeIndex': 480,\n",
       " 'GeneratorExp': 481,\n",
       " 'Import:ABCDataFrame': 482,\n",
       " 'Import:ABCIndexClass': 483,\n",
       " 'Import:ABCSeries': 484,\n",
       " 'Import:AbstractMethodError': 485,\n",
       " 'Import:TimedeltaArrayMixin': 486,\n",
       " 'Import:compat': 487,\n",
       " 'Import:pandas': 488,\n",
       " 'ImportFrom:pandas.core.arrays.timedeltas': 489,\n",
       " 'ImportFrom:pandas.core.dtypes.generic': 490,\n",
       " 'ImportFrom:pandas.errors': 491,\n",
       " 'ImportFrom:pd': 492,\n",
       " 'Name:ABCDataFrame': 493,\n",
       " 'Name:ABCIndexClass': 494,\n",
       " 'Name:AbstractMethodError': 495,\n",
       " 'Name:NotImplementedError': 496,\n",
       " 'Name:TimedeltaArrayMixin': 497,\n",
       " 'Name:_DtypeOpsMixin': 498,\n",
       " 'Name:_metadata': 499,\n",
       " 'Name:all': 500,\n",
       " 'Name:asobj': 501,\n",
       " 'Name:attr': 502,\n",
       " 'Name:dti': 503,\n",
       " 'Name:dti2': 504,\n",
       " 'Name:hash': 505,\n",
       " 'Name:list': 506,\n",
       " 'Name:na_value': 507,\n",
       " 'Name:pi': 508,\n",
       " 'Name:pi2': 509,\n",
       " 'Name:tdi': 510,\n",
       " 'Name:tdi2': 511,\n",
       " 'Name:tuple': 512,\n",
       " 'Name:tz_naive_fixture': 513,\n",
       " 'PeriodIndex': 514,\n",
       " 'TimedeltaIndex': 515,\n",
       " '__eq__': 516,\n",
       " '_metadata': 517,\n",
       " 'arg:other': 518,\n",
       " 'arg:string': 519,\n",
       " 'arg:tz_naive_fixture': 520,\n",
       " 'construct_from_string': 521,\n",
       " 'date_range': 522,\n",
       " 'period_range': 523,\n",
       " 'string_types': 524,\n",
       " 'PY2': 525,\n",
       " 'skipif': 526,\n",
       " 'Import:algorithms': 527,\n",
       " 'Import:base': 528,\n",
       " 'Import:common': 529,\n",
       " 'Import:console': 530,\n",
       " 'Import:format': 531,\n",
       " 'Import:nanops': 532,\n",
       " 'Import:ops': 533,\n",
       " 'Import:pandas.core.algorithms': 534,\n",
       " 'Import:pandas.core.common': 535,\n",
       " 'Import:pandas.core.indexes.base': 536,\n",
       " 'Import:pandas.core.nanops': 537,\n",
       " 'Import:pandas.core.ops': 538,\n",
       " 'Import:pandas.io.formats.console': 539,\n",
       " 'Import:pandas.io.formats.format': 540,\n",
       " 'ImportFrom:algorithms': 541,\n",
       " 'ImportFrom:console': 542,\n",
       " 'ImportFrom:nanops': 543,\n",
       " 'ImportFrom:ops': 544,\n",
       " 'ImportFrom:pandas.compat': 545,\n",
       " 'ImportFrom:pandas.core': 546,\n",
       " 'ImportFrom:pandas.core.indexes': 547,\n",
       " 'ImportFrom:pandas.io.formats': 548,\n",
       " 'l': 549,\n",
       " 's': 550,\n",
       " 'Import:concat': 551,\n",
       " 'Import:pandas.core.dtypes.concat': 552,\n",
       " 'ImportFrom:pandas.core.dtypes': 553,\n",
       " 'Import:DataFrame': 554,\n",
       " 'Import:Panel': 555,\n",
       " 'Name:ax': 556,\n",
       " 'Name:len_axis': 557,\n",
       " 'Name:len_indexer': 558,\n",
       " 'Name:target_len': 559,\n",
       " 'Name:values_len': 560,\n",
       " 'Import:internals': 561,\n",
       " 'Import:pandas.core.internals': 562,\n",
       " 'ImportFrom:internals': 563,\n",
       " 'Name:unpacked_obj': 564,\n",
       " 'Import:u_safe': 565,\n",
       " 'ImportFrom:u': 566,\n",
       " 'Name:sorted_series': 567,\n",
       " 'Name:u': 568,\n",
       " 'Name:key': 569,\n",
       " 'Name:index': 570,\n",
       " 'Name:obj': 571,\n",
       " 'attrs': 572,\n",
       " 'Name:where': 573,\n",
       " 'group': 574,\n",
       " 'Name:v': 575,\n",
       " 'Name:block': 576,\n",
       " 'Name:node': 577,\n",
       " 'kind': 578,\n",
       " 'Name:kind': 579,\n",
       " '_v_attrs': 580,\n",
       " 'append': 581,\n",
       " 'Name:stop': 582,\n",
       " 'encoding': 583,\n",
       " 'Name:c': 584,\n",
       " 'table': 585,\n",
       " 'arg:key': 586,\n",
       " 'Name:columns': 587,\n",
       " 'Name:start': 588,\n",
       " 'errors': 589,\n",
       " 'stop': 590,\n",
       " '_handle': 591,\n",
       " 'Name:k': 592,\n",
       " 'Name:group': 593,\n",
       " 'Name:_tables': 594,\n",
       " 'start': 595,\n",
       " 'Name:data_columns': 596,\n",
       " 'Name:itemsize': 597,\n",
       " 'data': 598,\n",
       " 'Name:nrows': 599,\n",
       " 'cname': 600,\n",
       " 'Name:min_itemsize': 601,\n",
       " 'Name:inferred_type': 602,\n",
       " 'Name:_ensure_decoded': 603,\n",
       " 'Name:keys': 604,\n",
       " 'version': 605,\n",
       " 'Name:labels': 606,\n",
       " 'Name:encoding': 607,\n",
       " 'non_index_axes': 608,\n",
       " 'values_axes': 609,\n",
       " 'Name:idx': 610,\n",
       " 'Name:existing_table': 611,\n",
       " 'arg:obj': 612,\n",
       " 'where': 613,\n",
       " 'arg:where': 614,\n",
       " 'Name:converted': 615,\n",
       " 'typ': 616,\n",
       " 'Name:shape': 617,\n",
       " 'index_axes': 618,\n",
       " 'nan_rep': 619,\n",
       " 'Name:g': 620,\n",
       " 'arg:block': 621,\n",
       " 'Name:items': 622,\n",
       " 'Name:IndexCol': 623,\n",
       " 'data_columns': 624,\n",
       " 'Name:append': 625,\n",
       " 'Name:groups': 626,\n",
       " 'Name:info': 627,\n",
       " 'Name:enumerate': 628,\n",
       " 'info': 629,\n",
       " 'levels': 630,\n",
       " 'arg:values': 631,\n",
       " 'index_name': 632,\n",
       " 'Name:rows': 633,\n",
       " 'arg:encoding': 634,\n",
       " 'arg:stop': 635,\n",
       " 'Name:atom': 636,\n",
       " 'get': 637,\n",
       " 'Name:chunksize': 638,\n",
       " 'arg:start': 639,\n",
       " 'Name:index_name': 640,\n",
       " 'ndim': 641,\n",
       " 'Name:setattr': 642,\n",
       " 'Name:axes': 643,\n",
       " 'Name:d': 644,\n",
       " 'Name:path_or_buf': 645,\n",
       " 'itemsize': 646,\n",
       " 'metadata': 647,\n",
       " 'Name:store': 648,\n",
       " 'nrows': 649,\n",
       " 'Name:format': 650,\n",
       " 'arg:errors': 651,\n",
       " 'infer_axes': 652,\n",
       " 'Name:mode': 653,\n",
       " 'Name:blocks': 654,\n",
       " 'Name:errors': 655,\n",
       " 'Name:complib': 656,\n",
       " 'Name:pandas_kind': 657,\n",
       " 'coordinates': 658,\n",
       " 'Name:tables': 659,\n",
       " 'Name:table_type': 660,\n",
       " 'Name:str': 661,\n",
       " 'Name:mgr': 662,\n",
       " 'startswith': 663,\n",
       " 'Name:tt': 664,\n",
       " 'Name:pt': 665,\n",
       " 'AugAssign': 666,\n",
       " 'Name:nan_rep': 667,\n",
       " 'Lt': 668,\n",
       " 'Name:levels': 669,\n",
       " 'pos': 670,\n",
       " 'Name:b_items': 671,\n",
       " 'ravel': 672,\n",
       " 'Name:t': 673,\n",
       " 'selection': 674,\n",
       " 'Name:current': 675,\n",
       " 'Name:names': 676,\n",
       " 'Name:blk_items': 677,\n",
       " 'Name:filt': 678,\n",
       " 'is_table': 679,\n",
       " 'arg:append': 680,\n",
       " '_path': 681,\n",
       " 'Name:obj_type': 682,\n",
       " '_indexables': 683,\n",
       " 'parent': 684,\n",
       " 'write': 685,\n",
       " 'arg:kind': 686,\n",
       " 'NotIn': 687,\n",
       " 'Name:cols': 688,\n",
       " 'Int64Col': 689,\n",
       " 'Name:complevel': 690,\n",
       " 'Name:pprint_thing': 691,\n",
       " 'Name:ret': 692,\n",
       " 'kind_attr': 693,\n",
       " 'arg:value': 694,\n",
       " 'Name:ndim': 695,\n",
       " 'set_data': 696,\n",
       " 'Name:_table_mod': 697,\n",
       " 'write_array': 698,\n",
       " 'read_array': 699,\n",
       " 'Name:new_self': 700,\n",
       " 'Name:klass': 701,\n",
       " 'Name:codes': 702,\n",
       " 'get_storer': 703,\n",
       " 'Name:m': 704,\n",
       " 'read': 705,\n",
       " 'get_node': 706,\n",
       " 'Name:objs': 707,\n",
       " 'Name:field': 708,\n",
       " 'Name:table': 709,\n",
       " 'Name:indexes': 710,\n",
       " 'close': 711,\n",
       " 'Name:handler': 712,\n",
       " 'arg:columns': 713,\n",
       " 'Name:dc': 714,\n",
       " 'Name:coords': 715,\n",
       " 'meta': 716,\n",
       " 'Name:nindexes': 717,\n",
       " 'arg:min_itemsize': 718,\n",
       " '_mode': 719,\n",
       " 'Name:categories': 720,\n",
       " 'chunksize': 721,\n",
       " 'table_type': 722,\n",
       " 'join': 723,\n",
       " '_filters': 724,\n",
       " 'scope_level': 725,\n",
       " 'Name:f': 726,\n",
       " 'arg:nan_rep': 727,\n",
       " 'validate_read': 728,\n",
       " 'Name:selector': 729,\n",
       " '_v_pathname': 730,\n",
       " 'Name:path': 731,\n",
       " 'names': 732,\n",
       " 'Name:indexer': 733,\n",
       " 'Name:blk': 734,\n",
       " 'items': 735,\n",
       " 'Name:e': 736,\n",
       " 'write_index': 737,\n",
       " 'Name:pos': 738,\n",
       " 'condition': 739,\n",
       " 'Name:lib': 740,\n",
       " 'Name:existing_col': 741,\n",
       " 'Name:transposed': 742,\n",
       " 'filter': 743,\n",
       " 'Name:col': 744,\n",
       " 'extend': 745,\n",
       " 'Name:HDFStore': 746,\n",
       " 'Name:column': 747,\n",
       " 'Name:ws': 748,\n",
       " 'arg:info': 749,\n",
       " 'Name:new_store': 750,\n",
       " 'LtE': 751,\n",
       " 'Name:cname': 752,\n",
       " 'arg:index': 753,\n",
       " 'Name:kw': 754,\n",
       " 'Name:sorted_values': 755,\n",
       " 'Name:level_key': 756,\n",
       " 'read_index': 757,\n",
       " 'blocks': 758,\n",
       " 'infer_dtype': 759,\n",
       " '_complevel': 760,\n",
       " 'Name:dropna': 761,\n",
       " 'Name:auto_close': 762,\n",
       " 'Name:variety': 763,\n",
       " 'Name:ensure_index': 764,\n",
       " 'arg:complib': 765,\n",
       " 'arg:handler': 766,\n",
       " 'Name:MultiIndex': 767,\n",
       " 'arg:format': 768,\n",
       " 'obj': 769,\n",
       " 'complib': 770,\n",
       " 'Name:set': 771,\n",
       " 'mode': 772,\n",
       " 'Name:masks': 773,\n",
       " 'recursive': 774,\n",
       " 'Name:attrs': 775,\n",
       " 'Name:_ensure_term': 776,\n",
       " 'Name:output': 777,\n",
       " 'Name:q': 778,\n",
       " 'Name:attributes': 779,\n",
       " 'Name:empty_array': 780,\n",
       " 'Name:metadata': 781,\n",
       " 'arg:itemsize': 782,\n",
       " 'create_array': 783,\n",
       " 'arg:mode': 784,\n",
       " 'keys': 785,\n",
       " 'Name:child': 786,\n",
       " 'arg:chunksize': 787,\n",
       " 'type': 788,\n",
       " 'groups': 789,\n",
       " 'Name:start_i': 790,\n",
       " 'description': 791,\n",
       " 'Name:sorter': 792,\n",
       " 'remove_node': 793,\n",
       " 'Name:j': 794,\n",
       " 'arg:data_columns': 795,\n",
       " '_v_name': 796,\n",
       " 'Name:append_axis': 797,\n",
       " 'Name:end_i': 798,\n",
       " 'Name:axis_labels': 799,\n",
       " 'is_open': 800,\n",
       " 'Name:existing_value': 801,\n",
       " 'Name:PeriodIndex': 802,\n",
       " 'Name:axis_number': 803,\n",
       " 'prod': 804,\n",
       " 'nlevels': 805,\n",
       " 'Name:block_obj': 806,\n",
       " 'Name:lp': 807,\n",
       " 'Name:_stop': 808,\n",
       " 'Name:wp': 809,\n",
       " 'select': 810,\n",
       " 'Name:DataCol': 811,\n",
       " 'Name:new_path': 812,\n",
       " 'Name:version': 813,\n",
       " 'auto_close': 814,\n",
       " 'arg:complevel': 815,\n",
       " 'Name:remain_key': 816,\n",
       " 'Name:ln': 817,\n",
       " 'Name:frames': 818,\n",
       " 'Name:_start': 819,\n",
       " 'Name:config': 820,\n",
       " 'arg:fletcher32': 821,\n",
       " 'Name:sv': 822,\n",
       " 'Name:lev': 823,\n",
       " 'infer': 824,\n",
       " 'Name:exist_axis': 825,\n",
       " 'Name:fletcher32': 826,\n",
       " 'Name:zone': 827,\n",
       " 'Name:date': 828,\n",
       " 'Name:_set_tz': 829,\n",
       " 'Name:ordered': 830,\n",
       " 'Name:ov': 831,\n",
       " 'Name:valid_index': 832,\n",
       " 'asi8': 833,\n",
       " 'Name:detail': 834,\n",
       " 'Name:long_index': 835,\n",
       " 'ordered': 836,\n",
       " 'Name:lab': 837,\n",
       " 'filters': 838,\n",
       " 'insert': 839,\n",
       " 'Name:wlist': 840,\n",
       " 'obj_type': 841,\n",
       " 'Continue': 842,\n",
       " 'cvalues': 843,\n",
       " 'Name:w': 844,\n",
       " 'indexables': 845,\n",
       " 'StringCol': 846,\n",
       " 'complevel': 847,\n",
       " 'fromtimestamp': 848,\n",
       " 'fill_value': 849,\n",
       " 'Name:sorted': 850,\n",
       " 'Name:axis_name': 851,\n",
       " 'value_type': 852,\n",
       " 'Mult': 853,\n",
       " 'Name:bi': 854,\n",
       " 'put': 855,\n",
       " 'Name:block_items': 856,\n",
       " 'set_name': 857,\n",
       " 'is_an_indexable': 858,\n",
       " 'Name:tbls': 859,\n",
       " 'Name:it': 860,\n",
       " 'Name:_unconvert_string_array': 861,\n",
       " 'default_fill_value': 862,\n",
       " 'Name:temp': 863,\n",
       " 'fletcher32': 864,\n",
       " 'Name:repeater': 865,\n",
       " 'arg:group': 866,\n",
       " 'Name:existing_kind': 867,\n",
       " 'Name:label_key': 868,\n",
       " 'Name:ordd': 869,\n",
       " 'arg:dropna': 870,\n",
       " 'pandas_type': 871,\n",
       " 'Name:p': 872,\n",
       " 'stacklevel': 873,\n",
       " 'Name:zip': 874,\n",
       " 'dtype_attr': 875,\n",
       " 'Name:item': 876,\n",
       " 'Name:min': 877,\n",
       " 'split': 878,\n",
       " 'is_indexed': 879,\n",
       " 'Name:N': 880,\n",
       " 'Name:fn': 881,\n",
       " 'flush': 882,\n",
       " '_check_if_open': 883,\n",
       " 'is_exists': 884,\n",
       " 'Name:iterator': 885,\n",
       " 'Name:_ensure_encoding': 886,\n",
       " 'read_coordinates': 887,\n",
       " 'Name:GenericFixed': 888,\n",
       " 'BinOp: Mult()': 889,\n",
       " 'pop': 890,\n",
       " 'terms': 891,\n",
       " '_create_storer': 892,\n",
       " 'Name:cols_': 893,\n",
       " '_fletcher32': 894,\n",
       " 'is_transposed': 895,\n",
       " 'Name:unique_tuples': 896,\n",
       " 'Name:IndexError': 897,\n",
       " 'T': 898,\n",
       " 'default_kind': 899,\n",
       " 'set_info': 900,\n",
       " 'Name:expectedrows': 901,\n",
       " 'Name:optlevel': 902,\n",
       " 'Name:takers': 903,\n",
       " 'Name:AppendableFrameTable': 904,\n",
       " 'Name:index_axes_map': 905,\n",
       " 'validate': 906,\n",
       " 'Name:_stringify_path': 907,\n",
       " 'Name:exists': 908,\n",
       " 'Name:Term': 909,\n",
       " 'Name:cur_metadata': 910,\n",
       " 'Name:os': 911,\n",
       " 'Name:cur_optlevel': 912,\n",
       " 'Name:BlockManager': 913,\n",
       " 'Name:_convert_index': 914,\n",
       " 'arg:cname': 915,\n",
       " 'Name:level': 916,\n",
       " 'arg:store': 917,\n",
       " 'arg:iterator': 918,\n",
       " 'Name:parent': 919,\n",
       " 'Name:data_converted': 920,\n",
       " 'min_itemsize': 921,\n",
       " 'Name:array_equivalent': 922,\n",
       " 'Name:kind_attr': 923,\n",
       " 'create_index': 924,\n",
       " 'Name:Table': 925,\n",
       " 'Import:tables': 926,\n",
       " 'dropna': 927,\n",
       " 'Name:libwriters': 928,\n",
       " 'Name:bvalues': 929,\n",
       " 'Name:inferred': 930,\n",
       " '_consolidate': 931,\n",
       " 'Name:new_blk_items': 932,\n",
       " 'Name:existing_dtype': 933,\n",
       " 'remove': 934,\n",
       " 'Name:axis_values': 935,\n",
       " 'Name:bindexes': 936,\n",
       " 'read_metadata': 937,\n",
       " 'fields': 938,\n",
       " 'Name:remain_values': 939,\n",
       " 'Name:tuple_index': 940,\n",
       " 'iterator': 941,\n",
       " 'Name:idxs': 942,\n",
       " 'Name:Warning': 943,\n",
       " 'Name:meta': 944,\n",
       " 'Name:error': 945,\n",
       " 'Name:pg': 946,\n",
       " 'float64': 947,\n",
       " 'Name:col_name': 948,\n",
       " 'validate_version': 949,\n",
       " 'labels': 950,\n",
       " 'Name:leaves': 951,\n",
       " 'storable': 952,\n",
       " 'Name:new_metadata': 953,\n",
       " 'chain': 954,\n",
       " 'Name:BlockManagerFixed': 955,\n",
       " 'ObjectAtom': 956,\n",
       " 'Name:sax': 957,\n",
       " 'Name:SparseSeriesFixed': 958,\n",
       " 'Name:slicer': 959,\n",
       " 'Name:diff': 960,\n",
       " 'arg:axes': 961,\n",
       " 'Name:lkeys': 962,\n",
       " 'Name:conv_level': 963,\n",
       " 'take_data': 964,\n",
       " 'Name:index_': 965,\n",
       " 'Name:DataIndexableCol': 966,\n",
       " '_AXIS_NAMES': 967,\n",
       " 'Name:ImportError': 968,\n",
       " 'cols': 969,\n",
       " 'Name:LegacyTable': 970,\n",
       " 'format_type': 971,\n",
       " 'index_cols': 972,\n",
       " 'set_pos': 973,\n",
       " 'Name:is_data_indexable': 974,\n",
       " 'Name:alias': 975,\n",
       " 'Name:oax': 976,\n",
       " 'values_cols': 977,\n",
       " 'Name:candidate_only_group': 978,\n",
       " 'Name:itertools': 979,\n",
       " 'Name:_get_tz': 980,\n",
       " 'nblocks': 981,\n",
       " 'arg:auto_close': 982,\n",
       " 'Name:fields': 983,\n",
       " 'Name:new_blocks': 984,\n",
       " 'Name:factory': 985,\n",
       " 'meta_attr': 986,\n",
       " 'queryables': 987,\n",
       " 'Name:concat': 988,\n",
       " '_complib': 989,\n",
       " 'Name:sdict': 990,\n",
       " 'Name:is_multi_index': 991,\n",
       " 'Name:is_shape_reversed': 992,\n",
       " 'Name:SparseFixed': 993,\n",
       " 'Name:get_blk_items': 994,\n",
       " 'Name:Selection': 995,\n",
       " 'set_kind': 996,\n",
       " 'Name:StringMixin': 997,\n",
       " '_v_depth': 998,\n",
       " 'Name:cur_kind': 999,\n",
       " 'tolist': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty matrix in size of all commits and number of tokens and try to import the number of each token per commit and developer into a new dataset\n",
    "vocab_range = len(vocab)+1\n",
    "cv_token = pd.DataFrame(0, index=np.arange(len(df_author_token)), columns=range(1,vocab_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding to extra columns: commit_author to store author name and commit_msg to seperate bug commits from others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_token['commit_Author'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_token['commit_msg']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>17613</th>\n",
       "      <th>17614</th>\n",
       "      <th>17615</th>\n",
       "      <th>17616</th>\n",
       "      <th>17617</th>\n",
       "      <th>17618</th>\n",
       "      <th>17619</th>\n",
       "      <th>17620</th>\n",
       "      <th>commit_Author</th>\n",
       "      <th>commit_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9095</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9098</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9099</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9100 rows × 17622 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1  2  3  4  5  6  7  8  9  10  ...  17613  17614  17615  17616  17617  \\\n",
       "0     0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "1     0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "2     0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "3     0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "4     0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "...  .. .. .. .. .. .. .. .. ..  ..  ...    ...    ...    ...    ...    ...   \n",
       "9095  0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "9096  0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "9097  0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "9098  0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "9099  0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "\n",
       "      17618  17619  17620  commit_Author  commit_msg  \n",
       "0         0      0      0              0           0  \n",
       "1         0      0      0              0           0  \n",
       "2         0      0      0              0           0  \n",
       "3         0      0      0              0           0  \n",
       "4         0      0      0              0           0  \n",
       "...     ...    ...    ...            ...         ...  \n",
       "9095      0      0      0              0           0  \n",
       "9096      0      0      0              0           0  \n",
       "9097      0      0      0              0           0  \n",
       "9098      0      0      0              0           0  \n",
       "9099      0      0      0              0           0  \n",
       "\n",
       "[9100 rows x 17622 columns]"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is an empty matrix of tokens\n",
    "cv_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df_author_token['tokens'][0]\n",
    "y= df_author_token['counts'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['Call']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for word in x:\n",
    "    if y[i]==0:\n",
    "        cv_token[word][0]+=1\n",
    "    else:\n",
    "        cv_token[word][0]+=y[i]\n",
    "print(cv_token[word][0])\n",
    "    #print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here based on the information in \"df_author_token\", I try to complate the \"cv_token\" by finding the number of that token for that specific commits and its author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\morad\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\morad\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "c:\\users\\morad\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\morad\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\morad\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "for row in df_author_token.iterrows():\n",
    "    y=0\n",
    "    temp_token = df_author_token['tokens'][x]\n",
    "    temp_count = df_author_token['counts'][x]\n",
    "    for word in temp_token:\n",
    "        if temp_count[y] == 0:\n",
    "            cv_token[vocab[word]][x]+=1\n",
    "            y+=1\n",
    "        else:\n",
    "            cv_token[vocab[word]][x]+=temp_count[y]\n",
    "            y+=1\n",
    "    cv_token['commit_Author'][x]=df_author_token['Author'][x]\n",
    "    cv_token['commit_msg'][x]=df_author_token['msg'][x]\n",
    "    x+=1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>17613</th>\n",
       "      <th>17614</th>\n",
       "      <th>17615</th>\n",
       "      <th>17616</th>\n",
       "      <th>17617</th>\n",
       "      <th>17618</th>\n",
       "      <th>17619</th>\n",
       "      <th>17620</th>\n",
       "      <th>commit_Author</th>\n",
       "      <th>commit_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>PERF: Faster Series.__getattribute__ (#20834)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>PERF: Faster Series.__getattribute__ (#20834)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>PERF: Faster Series.__getattribute__ (#20834)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>PERF: Faster Series.__getattribute__ (#20834)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tom Augspurger</td>\n",
       "      <td>PERF: Faster Series.__getattribute__ (#20834)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9095</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jbrockmendel</td>\n",
       "      <td>BUG: fix TypeError raised in maybe_downcast_nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9098</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Joris Van den Bossche</td>\n",
       "      <td>BUG/TST: ensure groupby.agg preserves extensio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9099</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Joris Van den Bossche</td>\n",
       "      <td>BUG/TST: ensure groupby.agg preserves extensio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9100 rows × 17622 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1  2  3  4  5  6  7  8  9  10  ...  17613  17614  17615  17616  17617  \\\n",
       "0      0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "1      1  1  1  1  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "2      2  1  1  0  1  1  1  1  3   1  ...      0      0      0      0      0   \n",
       "3      0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "4      2  1  0  1  0  1  0  0  1   1  ...      0      0      0      0      0   \n",
       "...   .. .. .. .. .. .. .. .. ..  ..  ...    ...    ...    ...    ...    ...   \n",
       "9095   3  0  0  0  1  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "9096   0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "9097   0  0  0  0  0  0  0  0  0   0  ...      0      0      0      0      0   \n",
       "9098   1  1  1  0  0  0  1  0  0   0  ...      0      0      0      0      0   \n",
       "9099  44  0  0  0  0  3  0  0  1   8  ...      0      0      0      0      0   \n",
       "\n",
       "      17618  17619  17620          commit_Author  \\\n",
       "0         0      0      0         Tom Augspurger   \n",
       "1         0      0      0         Tom Augspurger   \n",
       "2         0      0      0         Tom Augspurger   \n",
       "3         0      0      0         Tom Augspurger   \n",
       "4         0      0      0         Tom Augspurger   \n",
       "...     ...    ...    ...                    ...   \n",
       "9095      0      0      0           jbrockmendel   \n",
       "9096      0      0      0           jbrockmendel   \n",
       "9097      0      0      0           jbrockmendel   \n",
       "9098      0      0      0  Joris Van den Bossche   \n",
       "9099      1      1      1  Joris Van den Bossche   \n",
       "\n",
       "                                             commit_msg  \n",
       "0         PERF: Faster Series.__getattribute__ (#20834)  \n",
       "1         PERF: Faster Series.__getattribute__ (#20834)  \n",
       "2         PERF: Faster Series.__getattribute__ (#20834)  \n",
       "3         PERF: Faster Series.__getattribute__ (#20834)  \n",
       "4         PERF: Faster Series.__getattribute__ (#20834)  \n",
       "...                                                 ...  \n",
       "9095  BUG: fix TypeError raised in maybe_downcast_nu...  \n",
       "9096  BUG: fix TypeError raised in maybe_downcast_nu...  \n",
       "9097  BUG: fix TypeError raised in maybe_downcast_nu...  \n",
       "9098  BUG/TST: ensure groupby.agg preserves extensio...  \n",
       "9099  BUG/TST: ensure groupby.agg preserves extensio...  \n",
       "\n",
       "[9100 rows x 17622 columns]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv_token is a huge sparse matrix\n",
    "cv_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sperating bug commits and code commits\n",
    "Bug_tokenizer=cv_token[cv_token['commit_msg'].str.startswith(\"BUG\")]\n",
    "Source_tokenizer=cv_token[-cv_token['commit_msg'].str.startswith(\"BUG\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bug_tokenizer = Bug_tokenizer.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. KNN method on AST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the train and test set based same as pervious dataset.\n",
    "#the difference is here we have the vectorized matrix and we only need to calculate tf-idf of each token\n",
    "X_train_tokens  = Source_tokenizer.drop(['commit_Author', 'commit_msg'], axis=1)\n",
    "X_test_tokens  = Bug_tokenizer.drop(['commit_Author', 'commit_msg','index'], axis=1)\n",
    "Y_train_tokens = Source_tokenizer['commit_Author']\n",
    "Y_test_tokens = Bug_tokenizer['commit_Author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8455, 17620)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating the tf-idf matrix\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_tokens)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8455x17620 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 222096 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8455, 17622)"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Source_tokenizer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<645x17620 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14260 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf = tfidf_transformer.transform(X_test_tokens)\n",
    "X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1,6)\n",
    "score={}\n",
    "AST_score=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in 1 neighbor is: 33.33333333333333\n",
      "The accuracy in 2 neighbor is: 27.286821705426355\n",
      "The accuracy in 3 neighbor is: 27.131782945736433\n",
      "The accuracy in 4 neighbor is: 26.046511627906977\n",
      "The accuracy in 5 neighbor is: 26.82170542635659\n"
     ]
    }
   ],
   "source": [
    "for k in k_range:\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_tfidf,Y_train_tokens)\n",
    "    y_predict = knn.predict(X_test_tfidf)\n",
    "    score= accuracy_score(Y_test_tokens, y_predict)*100\n",
    "    AST_score.append(score)\n",
    "    print(\"The accuracy in {} neighbor is: {}\".format(k, score))\n",
    "    #score_list.append(score[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. LDA method on AST data\n",
    " * Here we are going to do the same step for LDA as pervious but this time in AST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_model_ast = LatentDirichletAllocation(n_components=10,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_LDA_tokens = cv_token.drop(['commit_Author', 'commit_msg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_tokens)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9100, 17620)"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_LDA_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model_ast.fit(All_LDA_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17620"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_vocab = list(vocab)\n",
    "len(list_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12650, 33402, 25823, 20440, 15890, 15189, 11245, 20052, 12220,\n",
       "       14116, 13306, 20050, 12982, 21995, 19155, 33424, 23273, 18731,\n",
       "       13031, 24012, 11923, 24810, 18410, 17525, 24745], dtype=int64)"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(LDA_model.components_)[0].argsort()[-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 20 WORDS FOR domain #0\n",
      "['periods', 'parametrize', 'resample', 'Lambda', 'Dict', 'freq', 'Tuple', 'NameConstant', 'index', 'mark', 'match', 'Name:expected', 'arg:self', 'Name:msg', 'Name:pd', 'Name:result', 'Name:pytest', 'With', 'withitem', 'FunctionDef', 'Num', 'arguments', 'List', 'Call', 'Str']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #1\n",
      "['left', 'Name:cat', 'Name:closed', 'Name:period_range', 'Name:rvalues', 'Tuple', 'string_types', 'ImportFrom:pandas.compat', 'Name:target', 'Name:bool', 'NameConstant', 'Import:pandas.compat', 'ImportFrom:compat', 'Import:range', 'Name:PeriodIndex', 'Import:compat', 'ImportFrom:pandas', 'skipna', 'format', 'BinOp: Mod()', 'Mod', 'Name:compat', 'Name:left', 'Name:right', 'Name:str']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #2\n",
      "['ImportFrom:tm', 'arg:request', 'For', 'Name:arr', 'Name:request', 'dtype', 'random', 'ClassDef', 'Name:b', 'xfail', 'param', 'Name:msg', 'Name:a', 'fixture', 'parametrize', 'assert_raises_regex', 'mark', 'withitem', 'With', 'match', 'nan', 'raises', 'Name:np', 'Name:tm', 'Name:pytest']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #3\n",
      "['Import:ensure_index', 'arg:level', 'values_from_object', 'arg:merge_cells', 'Name:ensure_index', 'Name:nv', 'Name:Appender', 'Name:f', 'arg:self', 'Name:nanops', 'BinOp: Mod()', 'Mod', 'Name:axis', 'header', 'Name:NotImplementedError', 'join', 'level', 'Name:pd', 'arg:engine', 'Name:com', 'Name:end', 'Name:_shared_docs', 'Name:start', 'NameConstant', 'read_excel']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #4\n",
      "['array', 'raises', 'arg:self', 'Tuple', 'Name:TypeError', 'BinOp: Sub()', 'Sub', 'Index', 'dtype', 'Mult', 'BinOp: Mult()', 'Assert', 'Name:pytest', 'Name:idx', 'Name:np', 'NameConstant', 'Compare', 'BinOp: Add()', 'Name:tm', 'Add', 'Name:expected', 'Name:other', 'Name:result', 'Name:pd', 'Call']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #5\n",
      "['Name:TypeError', 'ImportFrom:__future__', '_data', 'Name:ImportError', 'ClassDef', 'Name:ValueError', 'Name:Timestamp', 'Name:Exception', 'Raise', 'Name:com', 'Name:tslib', 'Name:DatetimeArray', 'Name:date_range', 'Pass', 'tz_localize', 'IsNot', 'stacklevel', 'warn', 'Name:DatetimeIndex', 'Try', 'Name:warnings', 'ExceptHandler', 'Name:FutureWarning', 'Name:tz', 'tz']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #6\n",
      "['Name:result', 'Name:ax', 'axis', 'Raise', 'comprehension', 'Name:isinstance', 'Eq', 'Name:np', 'UnaryOp', 'Name:len', 'Name:values', 'Tuple', 'arg:self', 'FunctionDef', 'arguments', 'Compare', 'Index', 'Return', 'Subscript', 'Num', 'Str', 'NameConstant', 'If', 'Call', 'Name:self']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #7\n",
      "['NotEq', 'Name:msg', 'name', 'Name:start', 'assert_produces_warning', 'Name:Timedelta', 'Name:FutureWarning', 'Lambda', 'Name:object', 'Name:f', 'withitem', 'With', 'Name:op', 'Name:end', 'arg:x', 'Name:operator', 'Name:catch_warnings', '__name__', 'Name:frequencies', 'Name:cls', 'record', 'Name:x', 'freq', 'Name:freq', 'NameConstant']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #8\n",
      "['UnaryOp', 'Slice', 'Name:pytest', 'Name:Series', 'Name:s', 'index', 'Eq', 'arg:self', 'Tuple', 'Assert', 'Compare', 'FunctionDef', 'arguments', 'NameConstant', 'Index', 'Name:np', 'Subscript', 'Name:df', 'Name:tm', 'Name:result', 'Name:expected', 'List', 'Str', 'Num', 'Call']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR domain #9\n",
      "['And', 'BoolOp: And()', 'Name:isinstance', 'Name:result', 'Name:data', 'Not', 'UnaryOp', 'Index', 'Eq', 'arg:self', 'Num', 'Subscript', 'dtype', 'Name:dtype', 'Name:np', 'Name:self', 'Tuple', 'FunctionDef', 'arguments', 'Return', 'Compare', 'If', 'NameConstant', 'Str', 'Call']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,domain in enumerate(LDA_model_ast.components_):\n",
    "    print(f'THE TOP 20 WORDS FOR domain #{index}')\n",
    "    print([list_vocab[i] for i in domain.argsort()[-25:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "AST_domain_results = LDA_model_ast.transform(All_LDA_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_token['domain'] = AST_domain_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "AST_Bug_LDA=cv_token[cv_token['commit_msg'].str.startswith(\"BUG\")]\n",
    "AST_Source_LDA=cv_token[-cv_token['commit_msg'].str.startswith(\"BUG\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "AST_Author_Domain=AST_Source_LDA[['commit_Author','domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "AST_Author_groupby=AST_Author_Domain.groupby(['commit_Author','domain']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "AST_Top_1_domain=AST_Author_groupby.groupby(['commit_Author'])['domain','count'].apply(lambda x: x.nlargest(2,columns=['count'])).reset_index()\n",
    "AST_Top_3_domain=AST_Author_groupby.groupby(['commit_Author'])['domain','count'].apply(lambda x: x.nlargest(3,columns=['count'])).reset_index()\n",
    "AST_Top_5_domain=AST_Author_groupby.groupby(['commit_Author'])['domain','count'].apply(lambda x: x.nlargest(5,columns=['count'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "AST_top_1_Au_domain = AST_Top_1_domain[['commit_Author','domain']]\n",
    "AST_top_3_Au_domain = AST_Top_3_domain[['commit_Author','domain']]\n",
    "AST_top_5_Au_domain = AST_Top_5_domain[['commit_Author','domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "AST_Top_1_Prediction=pd.merge(AST_Bug_LDA, AST_top_1_Au_domain, on='commit_Author')\n",
    "AST_Top_3_Prediction=pd.merge(AST_Bug_LDA, AST_top_3_Au_domain, on='commit_Author')\n",
    "AST_Top_5_Prediction=pd.merge(AST_Bug_LDA, AST_top_5_Au_domain, on='commit_Author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "AST_Accuracy_at_top1=(len(AST_Top_1_Prediction[(AST_Top_1_Prediction['domain_x']==AST_Top_1_Prediction['domain_y'])])/len(AST_Bug_LDA))*100\n",
    "AST_Accuracy_at_top3=(len(AST_Top_3_Prediction[(AST_Top_3_Prediction['domain_x']==AST_Top_3_Prediction['domain_y'])])/len(AST_Bug_LDA))*100\n",
    "AST_Accuracy_at_top5=(len(AST_Top_5_Prediction[(AST_Top_5_Prediction['domain_x']==AST_Top_5_Prediction['domain_y'])])/len(AST_Bug_LDA))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy @ Top 1 Domian: 43.72093023255814\n",
      "Accuracy @ Top 3 Domian: 55.03875968992248\n",
      "Accuracy @ Top 5 Domian: 79.68992248062015\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy @ Top 1 Domian:\" , AST_Accuracy_at_top1)\n",
    "print(\"Accuracy @ Top 3 Domian:\" , AST_Accuracy_at_top3)\n",
    "print(\"Accuracy @ Top 5 Domian:\" , AST_Accuracy_at_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Conclusion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = ['NLP','AST']\n",
    "data = [len(cv_code.get_feature_names()),len(list_vocab)]\n",
    "plt.barh(index, data)\n",
    "plt.xlabel('# of tokens', fontsize=5)\n",
    "plt.ylabel('Data type', fontsize=5)\n",
    "plt.title('Number of tokens per dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can find the number of token in AST method is less than NLP becuase AST considers more abstract tokens which are common in different python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NLP_LDA_Accuracy= [Accuracy_at_top1,Accuracy_at_top3,Accuracy_at_top5]\n",
    "AST_LDA_Accuracy = [AST_Accuracy_at_top1,AST_Accuracy_at_top3,AST_Accuracy_at_top5]\n",
    "index = np.arange(len(NLP_LDA_Accuracy))\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, NLP_LDA_Accuracy, bar_width,\n",
    "alpha=opacity,\n",
    "color='b',\n",
    "label='NLP')\n",
    "\n",
    "rects2 = plt.bar(index+bar_width, AST_LDA_Accuracy, bar_width,\n",
    "alpha=opacity,\n",
    "color='g',\n",
    "label='AST')\n",
    "\n",
    "plt.xlabel('Number of domain')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of LDA model in two dataset')\n",
    "plt.xticks(index + bar_width, ('Top 1 Domian','Top 3 Domian','Top 5 Domian'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can find in above chart, LDA shows a better result in AST data. It approves our hypothesis that AST can reflect the expertise of developers more semantically. \n",
    "Also we compare the result of LDA in both method with our baseline which is a KNN clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ae0fff3320>"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NLP_LDA_Accuracy= [Accuracy_at_top1,Accuracy_at_top3,Accuracy_at_top5]\n",
    "NLP_KNN_Accuracy = [NLP_score[0],NLP_score[2],NLP_score[4]]\n",
    "AST_LDA_Accuracy = [AST_Accuracy_at_top1,AST_Accuracy_at_top3,AST_Accuracy_at_top5]\n",
    "AST_KNN_Accuracy = [AST_score[0],AST_score[2],AST_score[4]]\n",
    "df=pd.DataFrame({'x': range(1,4), 'NLP_LDA': NLP_LDA_Accuracy, 'NLP_KNN': NLP_KNN_Accuracy, 'AST_LDA': AST_LDA_Accuracy, 'AST_KNN': AST_KNN_Accuracy })\n",
    "plt.plot( 'x', 'NLP_LDA', data=df, marker='o', markerfacecolor='blue', markersize=12, color='skyblue', linewidth=4)\n",
    "plt.plot( 'x', 'NLP_KNN', data=df, marker='o', markerfacecolor='purple', markersize=12, color='pink', linewidth=4)\n",
    "plt.plot( 'x', 'AST_LDA', data=df, marker='o', markerfacecolor='black', markersize=12, color='gray', linewidth=4)\n",
    "plt.plot( 'x', 'AST_KNN', data=df, marker='o', markerfacecolor='orange', markersize=12, color='brown', linewidth=4)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in above chart, \"AST_LDA\" has better accuracy than other methods. The accuracy of two classification methods decrease when we increase the number of K, becuase as we explain above, classification methods need more distiguished within the tokens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
